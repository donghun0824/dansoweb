import asyncio
import websockets 
import requests
import os  # 1. os ì„í¬íŠ¸
import pandas as pd
import pandas_ta as ta
import json
from datetime import datetime
import psycopg2  # 2. sqlite3 ëŒ€ì‹  psycopg2
import time
import httpx 
import firebase_admin # âœ… 1. firebase-admin ì„í¬íŠ¸
from firebase_admin import credentials, messaging # âœ… 2. ê´€ë ¨ ëª¨ë“ˆ ì„í¬íŠ¸
import sys
# --- (v12.0) API í‚¤ ì„¤ì • (ë³´ì•ˆ) ---
# 3. Render í™˜ê²½ ë³€ìˆ˜ì—ì„œ API í‚¤ë¥¼ ì½ì–´ì˜µë‹ˆë‹¤.
POLYGON_API_KEY = os.environ.get('POLYGON_API_KEY')
GEMINI_API_KEY = os.environ.get('GEMINI_API_KEY')
DISCORD_WEBHOOK_URL = os.environ.get('DISCORD_WEBHOOK_URL')

# âœ… 3. Firebase Admin SDK í™˜ê²½ ë³€ìˆ˜
FIREBASE_ADMIN_SDK_JSON_STR = os.environ.get('FIREBASE_ADMIN_SDK_JSON')

# --- (v15.3) Vertex AI ì„¤ì • (us-central1 ë³µê·€) ---
GCP_PROJECT_ID = "gen-lang-client-0379169283" 
# 1. ë¦¬ì „ì„ 'us-central1'ë¡œ ìœ ì§€
GCP_REGION = "us-central1" 

# --- âœ… 2. (NEW) Firebase VAPID í‚¤ (FCM ë°œì†¡ìš©) ---
VAPID_PRIVATE_KEY = os.environ.get('VAPID_PRIVATE_KEY') # (ì´ì œ pywebpushìš©ì´ë¼ ì‚¬ìš© ì•ˆ í•¨)
VAPID_EMAIL = "mailto:cbvkqtm98@gmail.com" # (ì´ì œ pywebpushìš©ì´ë¼ ì‚¬ìš© ì•ˆ í•¨)

# --- (v16.2) íŠœë‹ ë˜ëŒë¦¬ê¸° (API í•œë„ ë¬¸ì œ í•´ê²°) ---
MAX_PRICE = 10
TOP_N = 50
MIN_DATA_REQ = 6

# --- (v16.2) íŠœë‹ ë˜ëŒë¦¬ê¸° ---
WAE_MACD = (2, 3, 4) 
WAE_SENSITIVITY = 150
WAE_BB = (5, 1.5) 
WAE_ATR = 5 
WAE_ATR_MULT = 1.5
WAE_CMF = 5 
WAE_RSI_RANGE = (45, 75) # <-- âœ… 75ë¡œ ë³µê·€
RSI_LENGTH = 5 

# --- (v16.2) íŠœë‹ ë˜ëŒë¦¬ê¸° ---
ICHIMOKU_SHORT = (2, 3, 5) 
CLOUD_PROXIMITY = 20.0 # <-- âœ… 20.0ìœ¼ë¡œ ë³µê·€
CLOUD_THICKNESS = 0.5
OBV_LOOKBACK = 3 

# --- (v13.0) DB ê²½ë¡œ ì„¤ì • (PostgreSQL ì—°ë™) ---
# 4. Render í™˜ê²½ ë³€ìˆ˜ì—ì„œ PostgreSQL DB ì—°ê²° ì£¼ì†Œë¥¼ ì½ì–´ì˜µë‹ˆë‹¤.
DATABASE_URL = os.environ.get('DATABASE_URL')

def get_db_connection():
    """PostgreSQL DB ì—°ê²°ì„ ìƒì„±í•©ë‹ˆë‹¤."""
    # DATABASE_URLì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ëŠ”ì§€ í™•ì¸
    if not DATABASE_URL:
        raise ValueError("DATABASE_URL í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    conn = psycopg2.connect(DATABASE_URL)
    return conn

# âœ… 4. Firebase Admin SDK ì´ˆê¸°í™” í•¨ìˆ˜ (ìƒˆë¡œ ì¶”ê°€)
def init_firebase():
    """Firebase Admin SDKë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤."""
    try:
        if not FIREBASE_ADMIN_SDK_JSON_STR:
            print("âŒ [FCM] FIREBASE_ADMIN_SDK_JSONì´ ì„¤ì •ë˜ì§€ ì•Šì•„ FCMì„ ê±´ë„ˆëœë‹ˆë‹¤.")
            return False
        
        # í™˜ê²½ ë³€ìˆ˜ì—ì„œ JSON ë¬¸ìì—´ì„ ì½ì–´ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
        sdk_json_dict = json.loads(FIREBASE_ADMIN_SDK_JSON_STR)
        
        cred = credentials.Certificate(sdk_json_dict)
        
        # ì´ë¯¸ ì´ˆê¸°í™”ë˜ì—ˆëŠ”ì§€ í™•ì¸ (Renderê°€ ì¬ì‹œì‘í•  ë•Œ ì˜¤ë¥˜ ë°©ì§€)
        if not firebase_admin._apps:
            # âœ… [ìˆ˜ì •] .json íŒŒì¼ì— projectIdê°€ ì´ë¯¸ ìˆìœ¼ë¯€ë¡œ, ë”•ì…”ë„ˆë¦¬ ë®ì–´ì“°ê¸° ì œê±°
            firebase_admin.initialize_app(cred)
            
        print(f"âœ… [FCM] Firebase Admin SDK ì´ˆê¸°í™” ì„±ê³µ (Project ID: {sdk_json_dict.get('project_id')})")
        return True
    except Exception as e:
        print(f"âŒ [FCM] Firebase Admin SDK ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return False

ticker_minute_history = {} 
ticker_tick_history = {} 

# --- (v16.1) Gemini API í˜¸ì¶œ í•¨ìˆ˜ (AI ì‘ë‹µ ì˜¤ë¥˜ ìˆ˜ì •) ---
async def get_gemini_probability(ticker, conditions_data):
    if not GEMINI_API_KEY:
        print(f"-> [Gemini AI] {ticker}: GEMINI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•„ AI ë¶„ì„ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
        return 50 
    if not GCP_PROJECT_ID or "YOUR_PROJECT_ID" in GCP_PROJECT_ID:
        print(f"-> [Gemini AI] {ticker}: GCP_PROJECT_IDê°€ ì„¤ì •ë˜ì§€ ì•Šì•„ AI ë¶„ì„ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
        return 50

    system_prompt = """
You are a specialized scalping AI. Your task is to evaluate engine-qualified signals and return a "probability_score" (0~100) for short-term spikes (1~30 min).

---
STEP 1: Mandatory Engine Filter (MUST PASS)
-------------------------------------------
* A signal must pass at least one:
  - engine_1_pass (Explosion)
  - engine_2_pass (Setup)
* If BOTH are false:
    â†’ Invalid signal. Assign 10~20 and stop.

---
STEP 2: SCORING MODEL (v16.15) - Find the TWO "Good" Patterns
-------------------------------------------------------------
Check if the signal matches one of the two user-validated profitable patterns.

PATTERN A: "OVEREXTENSION SPIKE" (Profit Pattern 1)
--------------------------------------------------
* Conditions: The signal is "overextended" (high RSI or far above cloud).
  - RSI â‰¥ 72 OR cloud_distance â‰¥ 15%
* Score:
  â†’ 85~95 (This is a primary buy signal)

PATTERN B: "DIP & RIP SPIKE" (Profit Pattern 2)
------------------------------------------------
* Conditions: The signal is dipping *below* the cloud (like the chart).
  - cloud_distance < 0%
* Score:
  â†’ 80~90 (This is the *other* primary buy signal)

PATTERN C: "THE TRAP" (Loss Pattern)
-----------------------------------
* Conditions: If the signal is NOT Pattern A and NOT Pattern B.
  (This is the "safe" middle ground: RSI < 72 AND cloud_distance is 0~15%)
* User confirmed these signals DROP (-15%).
* Score:
  â†’ 20~40 (This is a trap. Strongly avoid.)

---
STEP 3: FINAL WEIGHTING
------------------------
* Apply bonuses to the score from STEP 2.
* Engine 1 (Explosion) â†’ add +3 to final score
* Volume_ok â†’ +2
* Chikou_ok â†’ +2

CAP final score at 97.

You must respond ONLY with the JSON schema:
{
  "probability_score": <int>,
  "reasoning": "<short explanation, mention Pattern A, B, or C>"
}
"""
    user_prompt = f"""
    Analyze the following signal data for Ticker: {ticker}
    {json.dumps(conditions_data, indent=2)}
    """
    
    # API URLì€ 'us-central1' ë¦¬ì „ ì‚¬ìš©
    api_url = (
        f"https://{GCP_REGION}-aiplatform.googleapis.com/v1/projects/{GCP_PROJECT_ID}"
        f"/locations/{GCP_REGION}/publishers/google/models/gemini-2.5-flash-lite:generateContent"
    )

    # "system" í”„ë¡¬í”„íŠ¸ì™€ "user" í”„ë¡¬í”„íŠ¸ë¥¼ í•˜ë‚˜ë¡œ í•©ì³ì„œ "user" ì—­í• ë¡œë§Œ ë³´ëƒ…ë‹ˆë‹¤.
    combined_prompt = f"{system_prompt}\n\n{user_prompt}"

    payload = {
        "contents": [
            {
                "role": "user", 
                "parts": [{"text": combined_prompt}]
            }
        ],
        "generationConfig": {
            "responseMimeType": "application/json"
        }
    }

    headers = {
        "Content-Type": "application/json",
        "x-goog-api-key": GEMINI_API_KEY
    }

    try:
        async with httpx.AsyncClient() as client:
            response = await client.post(api_url, json=payload, headers=headers, timeout=10.0)
            
            if not response.is_success:
                print(f"-> âŒ [Gemini AI] {ticker} ìš”ì²­ ì‹¤íŒ¨ (HTTP {response.status_code}): {response.text}")
                response.raise_for_status() 
                
            result = response.json()
            
            if 'candidates' not in result:
                if 'error' in result:
                     print(f"-> âŒ [Gemini AI] {ticker} Vertex AI ì˜¤ë¥˜: {result['error']['message']}")
                     return 50
                print(f"-> âŒ [Gemini AI] {ticker} ë¶„ì„ ì‹¤íŒ¨: ì‘ë‹µì— 'candidates' ì—†ìŒ. {result}")
                return 50

            response_text = result.get('candidates', [{}])[0].get('content', {}).get('parts', [{}])[0].get('text', '{}')
            
            # --- âœ… (v16.1) AIê°€ Markdownìœ¼ë¡œ ê°ì‹¸ì„œ ì‘ë‹µí•  ê²½ìš° JSON ì¶”ì¶œ ---
            if '```json' in response_text:
                print(f"-> [Gemini AI] {ticker}: Markdown ê°ì§€ë¨, JSON ì¶”ì¶œ ì‹œë„...")
                start = response_text.find('{')
                end = response_text.rfind('}') + 1
                if start != -1 and end != -1:
                    response_text = response_text[start:end]
            # --- ì—¬ê¸°ê¹Œì§€ ì¶”ê°€ ---
            
            if not response_text.strip().startswith('{'):
                print(f"-> âŒ [Gemini AI] {ticker} ë¶„ì„ ì‹¤íŒ¨: AIê°€ JSONì´ ì•„ë‹Œ í…ìŠ¤íŠ¸ë¡œ ì‘ë‹µí•¨. {response_text}")
                return 50

            score_data = json.loads(response_text)
            score = int(score_data.get("probability_score", 50))
            reasoning = score_data.get("reasoning", "No reasoning provided.")
            print(f"-> [Gemini AI] {ticker}: ìƒìŠ¹ í™•ë¥  {score}% (ì´ìœ : {reasoning})")
            return score
    except Exception as e:
        if 'response' not in locals(): 
            print(f"-> âŒ [Gemini AI] {ticker} ë¶„ì„ ì‹¤íŒ¨: {e}")
        return 50

# --- (v13.0) DB ì´ˆê¸°í™” í•¨ìˆ˜ (PostgreSQL ìš©) ---
def init_db():
    """PostgreSQL DBì™€ í…Œì´ë¸” 4ê°œë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    conn = None
    try:
        # 5. DATABASE_URLì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ëŠ”ì§€ í™•ì¸
        if not DATABASE_URL:
            print("âŒ [DB] DATABASE_URLì´ ì„¤ì •ë˜ì§€ ì•Šì•„ ì´ˆê¸°í™”ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
            return
            
        conn = get_db_connection()
        cursor = conn.cursor()
        
        # 6. PostgreSQLì— ë§ëŠ” í…Œì´ë¸” ìƒì„± (SERIAL = AUTOINCREMENT, TIMESTAMP)
        cursor.execute("""
        CREATE TABLE IF NOT EXISTS status (
            key TEXT PRIMARY KEY, 
            value TEXT NOT NULL, 
            last_updated TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        )
        """)

        cursor.execute("""
        CREATE TABLE IF NOT EXISTS signals (
            id SERIAL PRIMARY KEY, 
            ticker TEXT NOT NULL, 
            price REAL NOT NULL, 
            time TIMESTAMP NOT NULL
        )
        """)
        cursor.execute("""
        CREATE TABLE IF NOT EXISTS recommendations (
            id SERIAL PRIMARY KEY, 
            ticker TEXT NOT NULL UNIQUE, 
            price REAL NOT NULL, 
            time TIMESTAMP NOT NULL, 
            probability_score INTEGER
        )
        """)
        cursor.execute("""
        CREATE TABLE IF NOT EXISTS posts (
            id SERIAL PRIMARY KEY, 
            author TEXT NOT NULL, 
            content TEXT NOT NULL, 
            time TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        )
        """)
        
        # --- âœ… 3. FCM í† í° í…Œì´ë¸” ì¶”ê°€ (scanner.pyì—ë„ ì¶”ê°€) ---
        cursor.execute("""
        CREATE TABLE IF NOT EXISTS fcm_tokens (
            id SERIAL PRIMARY KEY,
            token TEXT NOT NULL UNIQUE,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        )
        """)
        # --- ì—¬ê¸°ê¹Œì§€ ì¶”ê°€ ---
        
        conn.commit()
        
        try:
            # 7. PostgreSQLìš© ALTER TABLE (ì—ëŸ¬ í•¸ë“¤ë§ìœ¼ë¡œ ì²˜ë¦¬)
            cursor.execute("ALTER TABLE recommendations ADD COLUMN probability_score INTEGER")
            conn.commit()
            print("-> [DB] 'recommendations' í…Œì´ë¸”ì— 'probability_score' ì»¬ëŸ¼ ì¶”ê°€ ì‹œë„ ì™„ë£Œ.")
        except psycopg2.Error as e:
            conn.rollback() # âœ… (v16.2) ë¡¤ë°± ì¶”ê°€
            if e.pgcode == '42701': # 'Duplicate Column' ì—ëŸ¬ ì½”ë“œ
                pass # ì»¬ëŸ¼ì´ ì´ë¯¸ ì¡´ì¬í•¨, ì •ìƒ
            else:
                # âœ… (v16.2) 502 ì˜¤ë¥˜ ë°©ì§€ë¥¼ ìœ„í•´ raise -> printë¡œ ë³€ê²½
                print(f"âŒ [DB] ALTER TABLE ì¤‘ ì˜ˆì™¸ ë°œìƒ (ë¬´ì‹œí•¨): {e}")
            
        cursor.close()
        conn.close()
        print(f"âœ… [DB] PostgreSQL í…Œì´ë¸” ì´ˆê¸°í™” ì„±ê³µ.")
    except Exception as e:
        if conn: 
            conn.rollback() # âœ… (v16.2) ë¡¤ë°± ì¶”ê°€
            conn.close()
        # âœ… (v16.2) 502 ì˜¤ë¥˜ ë°©ì§€ë¥¼ ìœ„í•´ raise -> printë¡œ ë³€ê²½
        print(f"âŒ [DB] PostgreSQL ì´ˆê¸°í™” ì‹¤íŒ¨ (ë¬´ì‹œí•¨): {e}")

# --- (v16.1) íŠœë‹: ì•Œë¦¼/ë¡œê·¸ í•¨ìˆ˜ ---
def send_discord_alert(ticker, price, type="signal", probability_score=50):
    if not DISCORD_WEBHOOK_URL or "YOUR_DISCORD" in DISCORD_WEBHOOK_URL or len(DISCORD_WEBHOOK_URL) < 50:
        print(f"ğŸ”” [ì•Œë¦¼] {ticker} @ ${price} (ë””ìŠ¤ì½”ë“œ URL ë¯¸ì„¤ì •)")
        return
        
    if type == "signal": 
        content = f"ğŸš€ **WAE í­ë°œ ì‹ í˜¸** ğŸš€\n**{ticker}** @ **${price:.4f}**\n**AI ìƒìŠ¹ í™•ë¥ : {probability_score}%**"
    else: 
        content = (
            f"ğŸ’¡ **AI Setup (Recommendation)** ğŸ’¡\n"
            f"**{ticker}** @ **${price:.4f}**\n"
            f"**AI Score: {probability_score}%**"
        )
        
    data = {"content": content}
    try: 
        requests.post(DISCORD_WEBHOOK_URL, json=data)
        print(f"ğŸ”” [ì•Œë¦¼] {ticker} @ ${price:.4f} (ë””ìŠ¤ì½”ë“œ ì „ì†¡ ì™„ë£Œ)")
    except Exception as e: 
        print(f"[ì•Œë¦¼ ì˜¤ë¥˜] {ticker} ë””ìŠ¤ì½”ë“œ ì „ì†¡ ì‹¤íŒ¨: {e}")

# --- (v16.10 ì¶”ì²œ) íŠœë‹: FCM í‘¸ì‹œ ì•Œë¦¼ ë°œì†¡ í•¨ìˆ˜ (êµ¬ì¡°í™”ëœ data í˜ì´ë¡œë“œ ì‚¬ìš©) ---
def send_fcm_notification(ticker, price, probability_score):
    """DBì˜ ëª¨ë“  ë¬¸ìì—´ í† í°ì— FCM 'data' í‘¸ì‹œ ì•Œë¦¼ì„ '1ê°œì”©' ë°œì†¡í•©ë‹ˆë‹¤."""
    
    if not firebase_admin._apps:
        print("ğŸ”” [FCM] Firebase Admin SDKê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•„ ì•Œë¦¼ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
        return

    conn = None
    try:
        conn = get_db_connection()
        # ... (í† í° ê°€ì ¸ì˜¤ëŠ” ë¡œì§ì€ ë™ì¼) ...
        cursor = conn.cursor()
        cursor.execute("SELECT token FROM fcm_tokens")
        tokens_list = [token[0] for token in cursor.fetchall() if token[0]] 
        cursor.close()
        conn.close()

        if not tokens_list:
            print("ğŸ”” [FCM] DBì— ë“±ë¡ëœ ì•Œë¦¼ êµ¬ë…ìê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        print(f"ğŸ”” [FCM] {len(tokens_list)}ëª…ì˜ êµ¬ë…ìì—ê²Œ {ticker} ì•Œë¦¼ '1ê°œì”©' ë°œì†¡ ì‹œë„...")
        
        # --- âœ… ì—¬ê¸°ê°€ í•µì‹¬ ìˆ˜ì • ì‚¬í•­ ---
        # 1. 'body' ëŒ€ì‹  PWA(sw.js)ê°€ ì‚¬ìš©í•  ì›ë³¸ ë°ì´í„°ë¥¼ ë³´ëƒ…ë‹ˆë‹¤.
        data_payload = {
            'title': "Danso AI ì‹ í˜¸", # PWAì—ì„œ ë®ì–´ì“¸ ìˆ˜ ìˆì§€ë§Œ ê¸°ë³¸ title
            
            # PWA(sw.js)ì—ì„œ ì¡°ë¦½í•  ìˆ˜ ìˆë„ë¡ ì›ë³¸ ë°ì´í„°ë¥¼ ì „ë‹¬
            'ticker': ticker,
            'price': f"{price:.4f}", # JSONì€ ìˆ«ìê°€ ê¼¬ì¼ ìˆ˜ ìˆìœ¼ë‹ˆ ë¬¸ìì—´ë¡œ í†µì¼
            'probability': str(probability_score) # ì´ê²ƒë„ ë¬¸ìì—´ë¡œ í†µì¼
            
            # 'icon'ì€ sw.jsê°€ ê¸°ë³¸ê°’ì„ ê°€ì§€ê³  ìˆìœ¼ë¯€ë¡œ ìƒëµ ê°€ëŠ¥
            # 'icon': '/static/images/danso_logo.png' 
        }
        # --- âœ… ìˆ˜ì • ì™„ë£Œ ---
        
        success_count = 0
        failure_count = 0
        failed_tokens = []

        for token in tokens_list:
            try:
                # 2. 'data='ë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒì€ í˜„ì¬ ì½”ë“œì™€ ë™ì¼ (ì•„ì£¼ ì˜ ë˜ì–´ ìˆìŒ)
                message = messaging.Message(
                    token=token,
                    data=data_payload, 
                    webpush=messaging.WebpushConfig(
                        headers={'Urgency': 'high'}
                    )
                )
                
                response = messaging.send(message)
                success_count += 1
                
            except Exception as e:
                # ... (ì´í•˜ ë™ì¼) ...
                print(f"âŒ [FCM] í† í° ì „ì†¡ ì‹¤íŒ¨: {token} (ì´ìœ : {e})")
                failure_count += 1
                if "Requested entity was not found" in str(e):
                    failed_tokens.append(token)
        
        print(f"âœ… [FCM] {success_count}ëª…ì—ê²Œ ë°œì†¡ ì™„ë£Œ, {failure_count}ëª… ì‹¤íŒ¨.")
        
        # 7. âœ… "Not Found" í† í°ë“¤ì„ DBì—ì„œ ì‚­ì œ
        if failed_tokens:
            try:
                conn = get_db_connection()
                cursor = conn.cursor()
                cursor.execute("DELETE FROM fcm_tokens WHERE token = ANY(%s)", (failed_tokens,))
                conn.commit()
                cursor.close()
                conn.close()
                print(f"ğŸ§¹ [FCM] ë§Œë£Œëœ í† í° {len(failed_tokens)}ê°œë¥¼ DBì—ì„œ ì‚­ì œí–ˆìŠµë‹ˆë‹¤.")
            except Exception as e:
                print(f"âŒ [FCM] ë§Œë£Œëœ í† í° DB ì‚­ì œ ì‹¤íŒ¨: {e}")

    except Exception as e:
        if conn: conn.close()
        print(f"âŒ [FCM] í‘¸ì‹œ ì•Œë¦¼ ë°œì†¡ ì¤‘ ì¹˜ëª…ì  ì˜¤ë¥˜: {e}")
          
# --- (v13.0) DB ë¡œê·¸ í•¨ìˆ˜ (PostgreSQL ìš©) ---
def log_signal(ticker, price, probability_score=50):
    conn = None
    try:
        conn = get_db_connection()
        cursor = conn.cursor()
        # 8. PostgreSQLìš© INSERT (%s ì‚¬ìš©, ? ëŒ€ì‹ )
        cursor.execute("INSERT INTO signals (ticker, price, time) VALUES (%s, %s, %s)", 
                       (ticker, price, datetime.now()))
        conn.commit()
        cursor.close()
        conn.close()
    except Exception as e:
        if conn: conn.close()
        print(f"âŒ [DB] 'signals' ì €ì¥ ì‹¤íŒ¨: {e}")

def log_recommendation(ticker, price, probability_score=50):
    conn = None
    try:
        conn = get_db_connection()
        cursor = conn.cursor()
        # 9. PostgreSQLìš© INSERT (ON CONFLICT DO NOTHING = IGNORE)
        cursor.execute("""
        INSERT INTO recommendations (ticker, price, time, probability_score) 
        VALUES (%s, %s, %s, %s)
        ON CONFLICT (ticker) DO NOTHING
        """, 
                       (ticker, price, datetime.now(), probability_score))
        conn.commit()
        is_new_rec = cursor.rowcount > 0
        cursor.close()
        conn.close()
        return is_new_rec
    except Exception as e:
        if conn: conn.close()
        print(f"âŒ [DB] 'recommendations' ì €ì¥ ì‹¤íŒ¨: {e}")
        return False

# --- 1ë‹¨ê³„ ë¡œì§: "ì˜¤ëŠ˜ì˜ ê´€ì‹¬ ì¡ì£¼" (v7.2) ---
def find_active_tickers():
    if not POLYGON_API_KEY:
        print(f"-> âŒ [ì‚¬ëƒ¥ê¾¼] 1ë‹¨ê³„ ìŠ¤ìº” ì˜¤ë¥˜: POLYGON_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return set()
        
    print(f"\n[ì‚¬ëƒ¥ê¾¼] 1ë‹¨ê³„: 'Top Gainers' (ì¡°ê±´: ${MAX_PRICE} ë¯¸ë§Œ) ìŠ¤ìº” ì¤‘...")
    
    # âœ… (ìˆ˜ì •) URLì„ ì˜¬ë°”ë¥¸ f-string í˜•ì‹ìœ¼ë¡œ ë³€ê²½
    url = f"https://api.polygon.io/v2/snapshot/locale/us/markets/stocks/gainers?apiKey={POLYGON_API_KEY}"

    tickers_to_watch = set()
    try:
        response = requests.get(url)
        response.raise_for_status() 
        data = response.json()
        if data.get('status') == 'OK':
            for ticker in data.get('tickers', []):
                price = ticker.get('lastTrade', {}).get('p', 999) 
                ticker_symbol = ticker.get('ticker')
                is_price_ok = price <= MAX_PRICE
                if is_price_ok and ticker_symbol:
                    tickers_to_watch.add(ticker_symbol)
                if len(tickers_to_watch) >= TOP_N: break
            print(f"-> [ì‚¬ëƒ¥ê¾¼] 1ë‹¨ê³„ ìŠ¤ìº” ì™„ë£Œ. ì´ {len(tickers_to_watch)}ê°œ ì¢…ëª© í¬ì°©.")
            
    except Exception as e:
        print(f"-> âŒ [ì‚¬ëƒ¥ê¾¼] 1ë‹¨ê³„ ìŠ¤ìº” ì˜¤ë¥˜ (API í‚¤/í•œë„ í™•ì¸): {e}")
        return tickers_to_watch # ì˜ˆì™¸ ë°œìƒ ì‹œ ë°˜í™˜
        
    # âœ… (ì¶”ê°€) ì„±ê³µ ì‹œì—ë„ í•­ìƒ setì„ ë°˜í™˜
    return tickers_to_watch

# --- 2ë‹¨ê³„ ë¡œì§: "v5.1 ëŠìŠ¨í•œ í†µí•© ì—”ì§„" (5ë¶„) ---
async def handle_msg(msg_data):
    global ticker_minute_history, ticker_tick_history
    m_fast, m_slow, m_sig = WAE_MACD; bb_len, bb_std = WAE_BB
    T, K, S = ICHIMOKU_SHORT
    
    TENKAN_COL = f"ITS_{T}"
    KIJUN_COL = f"IKS_{K}"
    SENKOU_A_COL = f"ISA_{T}"
    SENKOU_B_COL = f"ISB_{K}"
    CHIKOU_COL = f"ICS_{K}"
    
    # âœ… 2ë²ˆ ì§€ì  ì‚¬í•­ ë°˜ì˜: msg_dataê°€ dictì´ë©´ listë¡œ ê°ì‹¸ì„œ í¬ë˜ì‹œ ë°©ì§€
    if isinstance(msg_data, dict):
        msg_list = [msg_data]
    else:
        msg_list = msg_data

    minute_data = []
    for msg in msg_list:
        ticker = msg.get('sym')
        if not ticker:
            continue
            
        if msg.get('ev') == 'T':
            if ticker not in ticker_tick_history:
                ticker_tick_history[ticker] = []
            ticker_tick_history[ticker].append([msg.get('t'), msg.get('p'), msg.get('s')])
            if len(ticker_tick_history[ticker]) > 1000:
                ticker_tick_history[ticker] = ticker_tick_history[ticker][-1000:]
                
        elif msg.get('ev') == 'AM':
            print(f"-> [ì—”ì§„ v10.0] 1ë¶„ë´‰ ë°ì´í„° ìˆ˜ì‹ : {ticker} @ ${msg.get('c')} (Vol: {msg.get('v')})")
            minute_data.append(msg)

    for msg in minute_data:
        ticker = msg.get('sym')
        
        if ticker not in ticker_minute_history:
            ticker_minute_history[ticker] = pd.DataFrame(columns=['o', 'h', 'l', 'c', 'v', 't'])
            ticker_minute_history[ticker].set_index('t', inplace=True)
            
        timestamp = pd.to_datetime(msg.get('s'), unit='ms')
        new_row = {'o': msg.get('o'), 'h': msg.get('h'), 'l': msg.get('l'), 'c': msg.get('c'), 'v': msg.get('v')}
        ticker_minute_history[ticker].loc[timestamp] = new_row
        
        if len(ticker_minute_history[ticker]) > 60:
            ticker_minute_history[ticker] = ticker_minute_history[ticker].iloc[-60:]
        
        df_raw = ticker_minute_history[ticker].copy() 
        
        if len(df_raw) < MIN_DATA_REQ: continue

        df = df_raw.resample('1min').agg({
            'o': 'first', 'h': 'max', 'l': 'min', 'c': 'last', 'v': 'sum'
        })
        
        if ticker in ticker_tick_history and len(ticker_tick_history[ticker]) > 0:
            try:
                ticks_df = pd.DataFrame(ticker_tick_history[ticker], columns=['t', 'p', 's'])
                ticks_df['t'] = pd.to_datetime(ticks_df['t'], unit='ms')
                ticks_df.set_index('t', inplace=True)
                
                df['c'] = df['c'].combine_first(ticks_df['p'].resample('1min').last())
                df['o'] = df['o'].combine_first(ticks_df['p'].resample('1min').first())
                df['h'] = df['h'].combine_first(ticks_df['p'].resample('1min').max())
                df['l'] = df['l'].combine_first(ticks_df['p'].resample('1min').min())
                df['v'] = df['v'].combine_first(ticks_df['s'].resample('1min').sum())
                
                ticker_tick_history[ticker] = ticker_tick_history[ticker][-100:]

            except Exception as e:
                print(f"-> [v9.0 í‹± ë³´ê°„ ì‹¤íŒ¨] {ticker}: {e}")
                
        df.interpolate(method='linear', inplace=True)
        df.ffill(inplace=True)
        df.bfill(inplace=True)

        if len(df) < MIN_DATA_REQ: 
            continue 

        df.rename(columns={'c': 'close', 'h': 'high', 'l': 'low', 'o': 'open', 'v': 'volume'}, inplace=True)
        
        df.ta.macd(fast=m_fast, slow=m_slow, signal=m_sig, append=True)
        df.ta.bbands(length=bb_len, std=bb_std, append=True)
        df.ta.atr(length=WAE_ATR, append=True)
        df.ta.cmf(length=WAE_CMF, append=True) 
        df.ta.obv(append=True)
        df.ta.rsi(length=RSI_LENGTH, append=True) 
        df.ta.ichimoku(tenkan=T, kijun=K, senkou=S, append=True)
        
        MACD_COL = next((c for c in df.columns if c.startswith('MACD_')), None)
        BB_UP_COL = next((c for c in df.columns if c.startswith('BBU_')), None)
        BB_LOW_COL= next((c for c in df.columns if c.startswith('BBL_')), None)
        ATR_COL = next((c for c in df.columns if c.startswith('ATRr_')), None) 
        CMF_COL = next((c for c in df.columns if c.startswith('CMF_')), None)
        RSI_COL = next((c for c in df.columns if c.startswith('RSI_')), None)

        senkou_a_cols = [c for c in df.columns if c.startswith('ISA_') or c.startswith('SENKOU_A_')]
        senkou_b_cols = [c for c in df.columns if c.startswith('ISB_') or c.startswith('SENKOU_B_')]
        tenkan_cols   = [c for c in df.columns if c.startswith('ITS_') or c.startswith('TENKAN_')]
        kijun_cols    = [c for c in df.columns if c.startswith('IKS_') or c.startswith('KIJUN_')]
        chikou_cols   = [c for c in df.columns if c.startswith('ICS_') or c.startswith('CHIKOU_')]

        if not (MACD_COL and BB_UP_COL and BB_LOW_COL and ATR_COL and CMF_COL and
                RSI_COL and senkou_a_cols and senkou_b_cols and tenkan_cols and
                kijun_cols and chikou_cols):
            continue 
        
        SENKOU_A_COL = senkou_a_cols[0]; SENKOU_B_COL = senkou_b_cols[0]
        TENKAN_COL   = tenkan_cols[0];   KIJUN_COL    = kijun_cols[0]
        CHIKOU_COL   = chikou_cols[0]
        
        df['t1'] = (df[MACD_COL] - df[MACD_COL].shift(1)) * WAE_SENSITIVITY
        df['e1'] = df[BB_UP_COL] - df[BB_LOW_COL]
        df['deadZone'] = df[ATR_COL] * WAE_ATR_MULT
        
        if len(df) < MIN_DATA_REQ: continue 
            
        last = df.iloc[-1]; prev = df.iloc[-2]

        try:
            cond_wae_momentum = (last['t1'] > last['e1']) and (last['t1'] > last['deadZone'])
            cond_volume = (last[CMF_COL] > 0) and (last['OBV'] > prev['OBV'])
            cond_rsi = (WAE_RSI_RANGE[0] < last[RSI_COL] < WAE_RSI_RANGE[1]) # âœ… (v16.2) 75ë¡œ ë³µê·€

            cloud_a_current = df[SENKOU_A_COL].iloc[-K]; cloud_b_current = df[SENKOU_B_COL].iloc[-K]
            cloud_top = max(cloud_a_current, cloud_b_current); 
            is_above_cloud = last['close'] > cloud_top
            tk_cross_bullish = (prev[TENKAN_COL] < prev[KIJUN_COL]) and (last[TENKAN_COL] > last[KIJUN_COL])
            cond_ichimoku_trend = is_above_cloud and tk_cross_bullish
            
            cloud_thickness = abs(cloud_a_current - cloud_b_current) / last['close'] * 100
            dist_bull = (last['close'] - cloud_top) / last['close'] * 100
            
            # âœ… (v16.2) 20.0ìœ¼ë¡œ ë³µê·€
            cond_cloud_shape = (cloud_thickness >= CLOUD_THICKNESS) and (0 <= dist_bull <= CLOUD_PROXIMITY) 

            chikou = last[CHIKOU_COL] 
            price_K_ago = df['close'].iloc[-K] 
            cond_chikou = chikou > price_K_ago

            engine_1_pass = (cond_wae_momentum and cond_rsi)
            engine_2_pass = (cond_cloud_shape and cond_volume and cond_rsi)
            
            if engine_1_pass or engine_2_pass:
                
                conditions_data = {
                    "engine_1_pass (Explosion)": bool(engine_1_pass),
                    "engine_2_pass (Setup)": bool(engine_2_pass),
                    "wae_momentum": bool(cond_wae_momentum),
                    "rsi_ok": bool(cond_rsi),
                    "volume_ok": bool(cond_volume),
                    "cloud_shape_ok (20%)": bool(cond_cloud_shape), # (v16.2) ë³µê·€
                    "ichimoku_trend_ok": bool(cond_ichimoku_trend),
                    "chikou_ok": bool(cond_chikou),
                    "rsi_value": float(round(last[RSI_COL], 2)),
                    "cmf_value": float(round(last[CMF_COL], 2)),
                    "cloud_distance_percent": float(round(dist_bull, 2))
                }
                
                probability_score = await get_gemini_probability(ticker, conditions_data)
                
                print(f"ğŸ’¡ğŸ’¡ğŸ’¡ [í†µí•© ì—”ì§„ v5.1] {ticker} @ ${last['close']:.4f} (AI Score: {probability_score}%) ğŸ’¡ğŸ’¡ğŸ’¡")
                is_new_rec = log_recommendation(ticker, float(last['close']), probability_score)
                
                if is_new_rec: 
                    # âœ… (v16.2) ìˆ˜ì •ëœ í•¨ìˆ˜ (í’€ë°± ì•Œë¦¼ ì œê±°)
                    send_discord_alert(ticker, float(last['close']), "recommendation", probability_score)
                    send_fcm_notification(ticker, float(last['close']), probability_score)
            
            else:
                pass
                
        except Exception as e:
            print(f"-> âŒ [ì—”ì§„ CRASH] {ticker} ë¶„ì„ ì¤‘ ì¹˜ëª…ì  ì˜¤ë¥˜: {e}") 
            pass 

# --- (v7.2) ìˆ˜ì‹  ì—”ì§„ ---
async def websocket_engine(websocket):
    try:
        async for message in websocket:
            try:
                data_list = json.loads(message)
                await handle_msg(data_list) 
            except Exception as e:
                print(f"-> âŒ [v9.0 ìˆ˜ì‹  ì—”ì§„ CRASH] 'handle_msg' í˜¸ì¶œ ì‹¤íŒ¨: {e}")
                
    except websockets.exceptions.ConnectionClosed as e:
        print(f"-> âŒ [ì—”ì§„ v9.0] ì›¹ì†Œì¼“ ì—°ê²° ì¢…ë£Œ: {e.reason}") 
    except Exception as e:
        print(f"-> âŒ [ì—”ì§„ v9.0] ì›¹ì†Œì¼“ ì˜¤ë¥˜: {e}")

# --- (v16.2) íŠœë‹: 7ë¶„ë§ˆë‹¤ 'ì‚¬ëƒ¥ê¾¼' ì‹¤í–‰ (API í•œë„ ë³µê·€) ---
async def periodic_scanner(websocket):
    current_subscriptions = set() 
    
    while True:
        try:
            print(f"\n[ì‚¬ëƒ¥ê¾¼] (v16.2) 7ë¶„ ì£¼ê¸° ì‹œì‘. 'ì‹ í˜¸ í”¼ë“œ' (signals, recommendations) DBë¥¼ ì²­ì†Œí•©ë‹ˆë‹¤...")
            conn = get_db_connection()
            cursor = conn.cursor()
            # 10. PostgreSQLì€ TRUNCATEê°€ ë” ë¹ ë¦„ (DELETEë„ ì‘ë™ì€ í•¨)
            cursor.execute("TRUNCATE TABLE signals")
            cursor.execute("TRUNCATE TABLE recommendations")
            conn.commit()
            cursor.close()
            conn.close()
            print("-> [ì‚¬ëƒ¥ê¾¼] DB ì²­ì†Œ ì™„ë£Œ.")
        except Exception as e:
            print(f"-> âŒ [ì‚¬ëƒ¥ê¾¼] DB ì²­ì†Œ ì‹¤íŒ¨: {e}")
            
        new_tickers = find_active_tickers() 
        tickers_to_add = new_tickers - current_subscriptions
        tickers_to_remove = current_subscriptions - new_tickers
        
        try:
            if tickers_to_add:
                print(f"[ì‚¬ëƒ¥ê¾¼] {len(tickers_to_add)}ê°œ ì‹ ê·œ ì¢…ëª© (1ë¶„ë´‰+ê±°ë˜) 1ê°œì”© êµ¬ë… ì‹œì‘: {tickers_to_add}")
                for ticker in tickers_to_add:
                    params_str = f"AM.{ticker},T.{ticker}"
                    sub_payload = json.dumps({"action": "subscribe", "params": params_str})
                    await websocket.send(sub_payload)
                    await asyncio.sleep(0.1)
                print("[ì‚¬ëƒ¥ê¾¼] ì‹ ê·œ êµ¬ë… ì™„ë£Œ.")
                
            if tickers_to_remove:
                print(f"[ì‚¬ëƒ¥ê¾¼] {len(tickers_to_remove)}ê°œ ì‹ì€ ì¢…ëª© êµ¬ë… í•´ì§€: {tickers_to_remove}")
                for ticker in tickers_to_remove:
                    params_str = f"AM.{ticker},T.{ticker}"
                    unsub_payload = json.dumps({"action": "unsubscribe", "params": params_str})
                    await websocket.send(unsub_payload)
                    await asyncio.sleep(0.1)
                print("[ì‚¬ëƒ¥ê¾¼] êµ¬ë… í•´ì§€ ì™„ë£Œ.")
                
        except websockets.exceptions.ConnectionClosed:
             print("-> âŒ [ì‚¬ëƒ¥ê¾¼] êµ¬ë…/í•´ì§€ ì‹¤íŒ¨: ì›¹ì†Œì¼“ ì—°ê²°ì´ ì´ë¯¸ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. (ì¬ì—°ê²° ì‹œë„)")
             raise
        except Exception as e:
            print(f"-> âŒ [ì‚¬ëƒ¥ê¾¼] êµ¬ë…/í•´ì§€ ì‹¤íŒ¨: {e}")
            
        current_subscriptions = new_tickers
        
        status_tickers_list = []
        for ticker in current_subscriptions:
            status_tickers_list.append({"ticker": ticker, "is_new": ticker in tickers_to_add})
        status_data = {
            'last_scan_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            'watching_count': len(current_subscriptions),
            'watching_tickers': status_tickers_list
        }
        try:
            status_json_string = json.dumps(status_data)
            conn = get_db_connection()
            cursor = conn.cursor()
            # 11. PostgreSQLìš© INSERT (ON CONFLICT DO UPDATE)
            cursor.execute("""
            INSERT INTO status (key, value, last_updated) 
            VALUES (%s, %s, %s)
            ON CONFLICT (key) DO UPDATE SET
                value = EXCLUDED.value,
                last_updated = EXCLUDED.last_updated
            """,
                           ('status_data', status_json_string, datetime.now()))
            conn.commit()
            cursor.close()
            conn.close()
        except Exception as e:
            print(f"âŒ [DB] 'status' ì €ì¥ ì‹¤íŒ¨: {e}")
            
        # âœ… (íŠœë‹ 1) 1ë¶„(60ì´ˆ) -> 7ë¶„(420ì´ˆ)ë¡œ ë³µê·€
        print(f"\n[ì‚¬ëƒ¥ê¾¼] 7ë¶„(420ì´ˆ) í›„ ë‹¤ìŒ ìŠ¤ìº”ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
        await asyncio.sleep(420) 

# --- (v8.1) "ìˆ˜ë™ Keepalive" ë¡œë´‡ ---
async def manual_keepalive(websocket):
    try:
        while True:
            await websocket.ping()
            print("-> [Keepalive] Ping ì „ì†¡ (ì—°ê²° ìœ ì§€)")
            await asyncio.sleep(20)
    except websockets.exceptions.ConnectionClosed:
        print("-> [Keepalive] ì—°ê²° ì¢…ë£Œë¨. Ping ì¤‘ë‹¨.")
    except Exception as e:
        print(f"-> âŒ [Keepalive] í•‘ ì „ì†¡ ì¤‘ ì˜¤ë¥˜: {e}")

# --- ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜ (v9.0 - ìë™ ì¬ì—°ê²°) ---
async def main():
    if not POLYGON_API_KEY:
        print("âŒ [ë©”ì¸] POLYGON_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ìŠ¤ìºë„ˆë¥¼ ì‹œì‘í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    if not DATABASE_URL:
        print("âŒ [ë©”ì¸] DATABASE_URLì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ìŠ¤ìºë„ˆë¥¼ ì‹œì‘í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    # Vertex AIìš© í‚¤ í™•ì¸
    if not GEMINI_API_KEY:
        print("âŒ [ë©”ì¸] GEMINI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ìŠ¤ìºë„ˆë¥¼ ì‹œì‘í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    if not GCP_PROJECT_ID or "YOUR_PROJECT_ID" in GCP_PROJECT_ID:
        print("âŒ [ë©”ì¸] GCP_PROJECT_IDê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ìŠ¤ìºë„ˆë¥¼ ì‹œì‘í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # âœ… (ìˆ˜ì •) Firebase Admin SDK í‚¤ í™•ì¸
    if not FIREBASE_ADMIN_SDK_JSON_STR:
        print("âš ï¸ [ë©”ì¸] FIREBASE_ADMIN_SDK_JSONì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. FCM í‘¸ì‹œ ì•Œë¦¼ì´ ë¹„í™œì„±í™”ë©ë‹ˆë‹¤.")


    # âœ… (íŠœë‹) ë²„ì „ ì •ë³´ ìˆ˜ì •
    print("ìŠ¤ìºë„ˆ V16.7 (FCM-Admin SDK)ì„ ì‹œì‘í•©ë‹ˆë‹¤...") 
    uri = "wss://socket.polygon.io/stocks"
    
    while True:
        try:
            async with websockets.connect(uri, ping_interval=None, ping_timeout=300) as websocket:
                print(f"[ë©”ì¸] ì›¹ì†Œì¼“ {uri} ì—°ê²° ì„±ê³µ.")
                
                response = await websocket.recv()
                print(f"[ë©”ì¸] ì—°ê²° ì‘ë‹µ: {response}")
                if '"status":"connected"' not in str(response):
                     print("-> âŒ [ë©”ì¸] ë¹„ì •ìƒ ì—°ê²° ì‘ë‹µ. 10ì´ˆ í›„ ì¬ì‹œë„...")
                     await asyncio.sleep(10)
                     continue

                # 12. API í‚¤ê°€ Noneì´ ì•„ë‹Œì§€ í™•ì¸ (í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ ì‹¤íŒ¨ ëŒ€ë¹„)
                api_key_to_use = POLYGON_API_KEY or ""
                print(f"[ë©”ì¸] API í‚¤ ({api_key_to_use[:4]}...)ë¡œ 'ìˆ˜ë™ ì¸ì¦'ì„ ì‹œë„í•©ë‹ˆë‹¤...")
                auth_payload = json.dumps({"action": "auth", "params": api_key_to_use})
                await websocket.send(auth_payload)
                
                response = await websocket.recv()
                print(f"[ë©”ì¸] ì¸ì¦ ì‘ë‹µ: {response}")
                
                if '"status":"auth_success"' in str(response):
                    print("-> âœ… [ë©”ì¸] 'ìˆ˜ë™ ì¸ì¦' ì„±ê³µ! 3ê°œ ë¡œë´‡(ì‚¬ëƒ¥ê¾¼, ì—”ì§„, í•‘)ì„ ì‹œì‘í•©ë‹ˆë‹¤.")
                    
                    watcher_task = websocket_engine(websocket) 
                    scanner_task = periodic_scanner(websocket)
                    keepalive_task = manual_keepalive(websocket)
                    
                    await asyncio.gather(watcher_task, scanner_task, keepalive_task)
                else:
                    print("-> âŒ [ë©”ì¸] 'ìˆ˜ë™ ì¸ì¦' ì‹¤íŒ¨. 10ì´ˆ í›„ ì¬ì‹œë„...")
                    await asyncio.sleep(10)
                    continue
                    
        except websockets.exceptions.ConnectionClosed as e:
            print(f"-> âŒ [ë©”ì¸] ì›¹ì†Œì¼“ ì—°ê²°ì´ ì˜ˆê¸°ì¹˜ ì•Šê²Œ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤ ({e.code}). 10ì´ˆ í›„ ì¬ì—°ê²°í•©ë‹ˆë‹¤...")
            await asyncio.sleep(10)
        except Exception as e:
            print(f"-> âŒ [ë©”ì¸] ì¹˜ëª…ì  ì˜¤ë¥˜ ë°œìƒ: {e}. 10ì´ˆ í›„ ì¬ì—°ê²°í•©ë‹ˆë‹¤...")
            await asyncio.sleep(10)

# âœ… 5. __name__ == "__main__" ë¸”ë¡ ìˆ˜ì •
if __name__ == "__main__":
    init_db() 
    init_firebase() # âœ… Firebase ì´ˆê¸°í™” í˜¸ì¶œ ì¶”ê°€
    
    # âœ… [ìˆ˜ì •] 'test' ì¸ìê°€ ìˆëŠ”ì§€ í™•ì¸
    if len(sys.argv) > 1 and sys.argv[1] == 'test':
        print("--- [TEST MODE] ---")
        print("DBì™€ Firebase ì´ˆê¸°í™” ì™„ë£Œ. 3ì´ˆ í›„ í…ŒìŠ¤íŠ¸ ì•Œë¦¼ì„ ë°œì†¡í•©ë‹ˆë‹¤...")
        time.sleep(3) # (ë¡œê·¸ ë³¼ ì‹œê°„)
        
        # í…ŒìŠ¤íŠ¸ ì•Œë¦¼ ê°•ì œ ë°œì†¡
        send_fcm_notification(
            ticker="TEST", 
            price=123.45, 
            probability_score=99
        )
        
        print("--- [TEST MODE] í…ŒìŠ¤íŠ¸ ì™„ë£Œ. ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤. ---")
    
    else:
        # 'test' ì¸ìê°€ ì—†ìœ¼ë©´, (ê¸°ì¡´) ìŠ¤ìºë„ˆë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤.
        try: 
            print("--- [LIVE MODE] ìŠ¤ìºë„ˆë¥¼ ì‹œì‘í•©ë‹ˆë‹¤... ---")
            asyncio.run(main()) # âœ… asyncio ì˜¤íƒ€ ìˆ˜ì •
        except KeyboardInterrupt: 
            print("\n[ë©”ì¸] ì‚¬ìš©ìì— ì˜í•´ í”„ë¡œê·¸ë¨ì´ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")