import asyncio
import websockets 
import requests
import os  # 1. os ì„í¬íŠ¸
import pandas as pd
import pandas_ta as ta
import json
from datetime import datetime, timedelta
import psycopg2  # 2. sqlite3 ëŒ€ì‹  psycopg2
import time
import httpx 
import firebase_admin # âœ… 1. firebase-admin ì„í¬íŠ¸
from firebase_admin import credentials, messaging # âœ… 2. ê´€ë ¨ ëª¨ë“ˆ ì„í¬íŠ¸
import sys
import pytz
import traceback
# --- (v12.0) API í‚¤ ì„¤ì • (ë³´ì•ˆ) ---
# 3. Render í™˜ê²½ ë³€ìˆ˜ì—ì„œ API í‚¤ë¥¼ ì½ì–´ì˜µë‹ˆë‹¤.
POLYGON_API_KEY = os.environ.get('POLYGON_API_KEY')
GEMINI_API_KEY = os.environ.get('GEMINI_API_KEY')
DISCORD_WEBHOOK_URL = os.environ.get('DISCORD_WEBHOOK_URL')

# âœ… 3. Firebase Admin SDK í™˜ê²½ ë³€ìˆ˜
FIREBASE_ADMIN_SDK_JSON_STR = os.environ.get('FIREBASE_ADMIN_SDK_JSON')

# --- (v15.3) Vertex AI ì„¤ì • (us-central1 ë³µê·€) ---
GCP_PROJECT_ID = "gen-lang-client-0379169283" 
# 1. ë¦¬ì „ì„ 'us-central1'ë¡œ ìœ ì§€
GCP_REGION = "us-central1" 

# --- âœ… 2. (NEW) Firebase VAPID í‚¤ (FCM ë°œì†¡ìš©) ---
VAPID_PRIVATE_KEY = os.environ.get('VAPID_PRIVATE_KEY') # (ì´ì œ pywebpushìš©ì´ë¼ ì‚¬ìš© ì•ˆ í•¨)
VAPID_EMAIL = "mailto:cbvkqtm98@gmail.com" # (ì´ì œ pywebpushìš©ì´ë¼ ì‚¬ìš© ì•ˆ í•¨)

# --- (v16.2) íŠœë‹ ë˜ëŒë¦¬ê¸° (API í•œë„ ë¬¸ì œ í•´ê²°) ---
MAX_PRICE = 20
TOP_N = 100
MIN_DATA_REQ = 20

# --- (v16.2) íŠœë‹ ë˜ëŒë¦¬ê¸° ---
WAE_MACD = (2, 3, 4) 
WAE_SENSITIVITY = 150
WAE_BB = (5, 1.5) 
WAE_ATR = 5 
WAE_ATR_MULT = 1.5
WAE_CMF = 5 
WAE_RSI_RANGE = (40, 70) # <-- âœ… 75ë¡œ ë³µê·€
RSI_LENGTH = 5 

# --- (v16.2) íŠœë‹ ë˜ëŒë¦¬ê¸° ---
ICHIMOKU_SHORT = (2, 3, 5) 
CLOUD_PROXIMITY = 20.0 # <-- âœ… 20.0ìœ¼ë¡œ ë³µê·€
CLOUD_THICKNESS = 0.5
OBV_LOOKBACK = 3 

# --- (v13.0) DB ê²½ë¡œ ì„¤ì • (PostgreSQL ì—°ë™) ---
# 4. Render í™˜ê²½ ë³€ìˆ˜ì—ì„œ PostgreSQL DB ì—°ê²° ì£¼ì†Œë¥¼ ì½ì–´ì˜µë‹ˆë‹¤.
DATABASE_URL = os.environ.get('DATABASE_URL')

def get_db_connection():
    """PostgreSQL DB ì—°ê²°ì„ ìƒì„±í•©ë‹ˆë‹¤."""
    # DATABASE_URLì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ëŠ”ì§€ í™•ì¸
    if not DATABASE_URL:
        raise ValueError("DATABASE_URL í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    conn = psycopg2.connect(DATABASE_URL)
    return conn

# âœ… 4. Firebase Admin SDK ì´ˆê¸°í™” í•¨ìˆ˜ (ìƒˆë¡œ ì¶”ê°€)
def init_firebase():
    """Firebase Admin SDKë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤."""
    try:
        if not FIREBASE_ADMIN_SDK_JSON_STR:
            print("âŒ [FCM] FIREBASE_ADMIN_SDK_JSONì´ ì„¤ì •ë˜ì§€ ì•Šì•„ FCMì„ ê±´ë„ˆëœë‹ˆë‹¤.")
            return False
        
        # í™˜ê²½ ë³€ìˆ˜ì—ì„œ JSON ë¬¸ìì—´ì„ ì½ì–´ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
        sdk_json_dict = json.loads(FIREBASE_ADMIN_SDK_JSON_STR)
        
        cred = credentials.Certificate(sdk_json_dict)
        
        # ì´ë¯¸ ì´ˆê¸°í™”ë˜ì—ˆëŠ”ì§€ í™•ì¸ (Renderê°€ ì¬ì‹œì‘í•  ë•Œ ì˜¤ë¥˜ ë°©ì§€)
        if not firebase_admin._apps:
            # âœ… [ìˆ˜ì •] .json íŒŒì¼ì— projectIdê°€ ì´ë¯¸ ìˆìœ¼ë¯€ë¡œ, ë”•ì…”ë„ˆë¦¬ ë®ì–´ì“°ê¸° ì œê±°
            firebase_admin.initialize_app(cred)
            
        print(f"âœ… [FCM] Firebase Admin SDK ì´ˆê¸°í™” ì„±ê³µ (Project ID: {sdk_json_dict.get('project_id')})")
        return True
    except Exception as e:
        print(f"âŒ [FCM] Firebase Admin SDK ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return False

ticker_minute_history = {} 
ticker_tick_history = {} 

# --- (v16.1) Gemini API í˜¸ì¶œ í•¨ìˆ˜ (AI ì‘ë‹µ ì˜¤ë¥˜ ìˆ˜ì •) ---
async def get_gemini_probability(ticker, conditions_data):
    if not GEMINI_API_KEY:
        print(f"-> [Gemini AI] {ticker}: GEMINI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•„ AI ë¶„ì„ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
        return 50 
    if not GCP_PROJECT_ID or "YOUR_PROJECT_ID" in GCP_PROJECT_ID:
        print(f"-> [Gemini AI] {ticker}: GCP_PROJECT_IDê°€ ì„¤ì •ë˜ì§€ ì•Šì•„ AI ë¶„ì„ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
        return 50

    system_prompt = """
You are an elite **"Penny Stock Sniper AI"**.
You represent a strict scalper who only pulls the trigger on **PERFECT setups**.
**Your Rule:** It is better to miss a trade than to lose money.
**Score Inflation is Forbidden.** 90+ scores must be RARE and PERFECT.

**INPUT DATA Analysis:**
1. `pullback_from_high`: **The most critical filter.**
   - **> 12%:** BROKEN TREND. (Immediate Fail).
   - **< 5%:** ELITE STRENGTH. (High Tight Flag).
2. `pump_strength_5m`:
   - **> 3.0%:** Chasing. Too risky for a 90+ score.
3. `daily_change`: Indicates momentum.
4. `squeeze_ratio`: < 1.0 indicates stored energy.

---
### STRICT SCORING LOGIC

**ğŸ›‘ KILL SWITCH (The "FOXX" Filter)**
* **IF** `pullback_from_high` > 12.0%:
   â†’ **MAX SCORE = 40.** (Trend is broken. Do not catch a falling knife).
   â†’ *Reasoning: "Deep pullback (-x%) detected. Chart is broken."*

**ğŸ† Pattern A: "The King's Setup" (Rare & Perfect)**
* **Conditions (ALL must be met):**
   1. `pullback_from_high` < 5.0% (Holding gains like a rock)
   2. `squeeze_ratio` < 1.0 (Energy is tightly coiled)
   3. `pump_strength_5m` < 3.0% (Not currently spiking/chasing)
   4. `is_volume_dry` is True (Sellers are gone)
* **Verdict:** **SCORE 90~99** (Sniper Entry).

**ğŸ¥ˆ Pattern B: "Standard Momentum" (Good but Risky)**
* **Conditions:**
   - `pullback_from_high` is 5% ~ 12% (Normal volatility)
   - `engine_1_pass` (WAE) is True OR `squeeze_ratio` < 1.1
* **Verdict:** **SCORE 75~85** (Good trade, but not perfect).

**ğŸ—‘ï¸ Pattern C: "The Chase" or "The Dump"**
* **Conditions:**
   - `pump_strength_5m` > 4.0% (You are chasing)
   - OR `pullback_from_high` > 12% (Dump)
* **Verdict:** **SCORE 40~60** (Pass).

---
**Generate JSON Output:**
Respond ONLY with this JSON structure.
{
  "probability_score": <int>,
  "reasoning": "<[Grade] King/Standard/Trash? [Risk] Pullback: -x.x%. [Verdict] Why this specific score?>"
}
"""
    user_prompt = f"""
    Analyze the following signal data for Ticker: {ticker}
    
    [MARKET CONTEXT]
    - Current Session: {conditions_data.get('session_type', 'unknown')}
    - Volume Ratio: {conditions_data.get('volume_ratio', 0.0)}
    
    [TECHNICAL DATA]
    {json.dumps(conditions_data, indent=2)}
    """
    
    # API URLì€ 'us-central1' ë¦¬ì „ ì‚¬ìš©
    api_url = (
        f"https://{GCP_REGION}-aiplatform.googleapis.com/v1/projects/{GCP_PROJECT_ID}"
        f"/locations/{GCP_REGION}/publishers/google/models/gemini-2.5-flash-lite:generateContent"
    )

    # "system" í”„ë¡¬í”„íŠ¸ì™€ "user" í”„ë¡¬í”„íŠ¸ë¥¼ í•˜ë‚˜ë¡œ í•©ì³ì„œ "user" ì—­í• ë¡œë§Œ ë³´ëƒ…ë‹ˆë‹¤.
    combined_prompt = f"{system_prompt}\n\n{user_prompt}"

    payload = {
        "contents": [
            {
                "role": "user", 
                "parts": [{"text": combined_prompt}]
            }
        ],
        "generationConfig": {
            "responseMimeType": "application/json"
        }
    }

    headers = {
        "Content-Type": "application/json",
        "x-goog-api-key": GEMINI_API_KEY
    }

    try:
        async with httpx.AsyncClient() as client:
            response = await client.post(api_url, json=payload, headers=headers, timeout=10.0)
            
            if not response.is_success:
                print(f"-> âŒ [Gemini AI] {ticker} ìš”ì²­ ì‹¤íŒ¨ (HTTP {response.status_code}): {response.text}")
                response.raise_for_status() 
                
            result = response.json()
            
            if 'candidates' not in result:
                if 'error' in result:
                     print(f"-> âŒ [Gemini AI] {ticker} Vertex AI ì˜¤ë¥˜: {result['error']['message']}")
                     return 50
                print(f"-> âŒ [Gemini AI] {ticker} ë¶„ì„ ì‹¤íŒ¨: ì‘ë‹µì— 'candidates' ì—†ìŒ. {result}")
                return 50

            response_text = result.get('candidates', [{}])[0].get('content', {}).get('parts', [{}])[0].get('text', '{}')
            
            # --- âœ… (v16.1) AIê°€ Markdownìœ¼ë¡œ ê°ì‹¸ì„œ ì‘ë‹µí•  ê²½ìš° JSON ì¶”ì¶œ ---
            if '```json' in response_text:
                print(f"-> [Gemini AI] {ticker}: Markdown ê°ì§€ë¨, JSON ì¶”ì¶œ ì‹œë„...")
                start = response_text.find('{')
                end = response_text.rfind('}') + 1
                if start != -1 and end != -1:
                    response_text = response_text[start:end]
            # --- ì—¬ê¸°ê¹Œì§€ ì¶”ê°€ ---
            
            if not response_text.strip().startswith('{'):
                print(f"-> âŒ [Gemini AI] {ticker} ë¶„ì„ ì‹¤íŒ¨: AIê°€ JSONì´ ì•„ë‹Œ í…ìŠ¤íŠ¸ë¡œ ì‘ë‹µí•¨. {response_text}")
                return 50

            score_data = json.loads(response_text)
            score = int(score_data.get("probability_score", 50))
            reasoning = score_data.get("reasoning", "No reasoning provided.")
            print(f"-> [Gemini AI] {ticker}: ìƒìŠ¹ í™•ë¥  {score}% (ì´ìœ : {reasoning})")
            return score
    except Exception as e:
        if 'response' not in locals(): 
            print(f"-> âŒ [Gemini AI] {ticker} ë¶„ì„ ì‹¤íŒ¨: {e}")
        return 50

# --- (v13.0) DB ì´ˆê¸°í™” í•¨ìˆ˜ (PostgreSQL ìš©) ---
def init_db():
    """PostgreSQL DBì™€ í…Œì´ë¸” 4ê°œë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    conn = None
    try:
        # 5. DATABASE_URLì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ëŠ”ì§€ í™•ì¸
        if not DATABASE_URL:
            print("âŒ [DB] DATABASE_URLì´ ì„¤ì •ë˜ì§€ ì•Šì•„ ì´ˆê¸°í™”ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
            return
            
        conn = get_db_connection()
        cursor = conn.cursor()
        
        # 6. PostgreSQLì— ë§ëŠ” í…Œì´ë¸” ìƒì„± (SERIAL = AUTOINCREMENT, TIMESTAMP)
        cursor.execute("""
        CREATE TABLE IF NOT EXISTS status (
            key TEXT PRIMARY KEY, 
            value TEXT NOT NULL, 
            last_updated TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        )
        """)

        cursor.execute("""
        CREATE TABLE IF NOT EXISTS signals (
            id SERIAL PRIMARY KEY, 
            ticker TEXT NOT NULL, 
            price REAL NOT NULL, 
            time TIMESTAMP NOT NULL
        )
        """)
        cursor.execute("""
        CREATE TABLE IF NOT EXISTS recommendations (
            id SERIAL PRIMARY KEY, 
            ticker TEXT NOT NULL UNIQUE, 
            price REAL NOT NULL, 
            time TIMESTAMP NOT NULL, 
            probability_score INTEGER
        )
        """)
        cursor.execute("""
        CREATE TABLE IF NOT EXISTS posts (
            id SERIAL PRIMARY KEY, 
            author TEXT NOT NULL, 
            content TEXT NOT NULL, 
            time TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        )
        """)
        
        # --- âœ… 3. FCM í† í° í…Œì´ë¸” ì¶”ê°€ (scanner.pyì—ë„ ì¶”ê°€) ---
        cursor.execute("""
        CREATE TABLE IF NOT EXISTS fcm_tokens (
            id SERIAL PRIMARY KEY,
            token TEXT NOT NULL UNIQUE,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        )
        """)
        # --- ì—¬ê¸°ê¹Œì§€ ì¶”ê°€ ---
        
        conn.commit()
        
        try:
            # 7. PostgreSQLìš© ALTER TABLE (ì—ëŸ¬ í•¸ë“¤ë§ìœ¼ë¡œ ì²˜ë¦¬)
            cursor.execute("ALTER TABLE recommendations ADD COLUMN probability_score INTEGER")
            conn.commit()
            print("-> [DB] 'recommendations' í…Œì´ë¸”ì— 'probability_score' ì»¬ëŸ¼ ì¶”ê°€ ì‹œë„ ì™„ë£Œ.")
        except psycopg2.Error as e:
            conn.rollback() # âœ… (v16.2) ë¡¤ë°± ì¶”ê°€
            if e.pgcode == '42701': # 'Duplicate Column' ì—ëŸ¬ ì½”ë“œ
                pass # ì»¬ëŸ¼ì´ ì´ë¯¸ ì¡´ì¬í•¨, ì •ìƒ
            else:
                # âœ… (v16.2) 502 ì˜¤ë¥˜ ë°©ì§€ë¥¼ ìœ„í•´ raise -> printë¡œ ë³€ê²½
                print(f"âŒ [DB] ALTER TABLE ì¤‘ ì˜ˆì™¸ ë°œìƒ (ë¬´ì‹œí•¨): {e}")
            
        cursor.close()
        conn.close()
        print(f"âœ… [DB] PostgreSQL í…Œì´ë¸” ì´ˆê¸°í™” ì„±ê³µ.")
    except Exception as e:
        if conn: 
            conn.rollback() # âœ… (v16.2) ë¡¤ë°± ì¶”ê°€
            conn.close()
        # âœ… (v16.2) 502 ì˜¤ë¥˜ ë°©ì§€ë¥¼ ìœ„í•´ raise -> printë¡œ ë³€ê²½
        print(f"âŒ [DB] PostgreSQL ì´ˆê¸°í™” ì‹¤íŒ¨ (ë¬´ì‹œí•¨): {e}")

# --- (v16.1) íŠœë‹: ì•Œë¦¼/ë¡œê·¸ í•¨ìˆ˜ ---
def send_discord_alert(ticker, price, type="signal", probability_score=50):
    if not DISCORD_WEBHOOK_URL or "YOUR_DISCORD" in DISCORD_WEBHOOK_URL or len(DISCORD_WEBHOOK_URL) < 50:
        print(f"ğŸ”” [ì•Œë¦¼] {ticker} @ ${price} (ë””ìŠ¤ì½”ë“œ URL ë¯¸ì„¤ì •)")
        return
        
    if type == "signal": 
        content = f"ğŸš€ **WAE í­ë°œ ì‹ í˜¸** ğŸš€\n**{ticker}** @ **${price:.4f}**\n**AI ìƒìŠ¹ í™•ë¥ : {probability_score}%**"
    else: 
        content = (
            f"ğŸ’¡ **AI Setup (Recommendation)** ğŸ’¡\n"
            f"**{ticker}** @ **${price:.4f}**\n"
            f"**AI Score: {probability_score}%**"
        )
        
    data = {"content": content}
    try: 
        requests.post(DISCORD_WEBHOOK_URL, json=data)
        print(f"ğŸ”” [ì•Œë¦¼] {ticker} @ ${price:.4f} (ë””ìŠ¤ì½”ë“œ ì „ì†¡ ì™„ë£Œ)")
    except Exception as e: 
        print(f"[ì•Œë¦¼ ì˜¤ë¥˜] {ticker} ë””ìŠ¤ì½”ë“œ ì „ì†¡ ì‹¤íŒ¨: {e}")

# --- (v16.10 ì¶”ì²œ) íŠœë‹: FCM í‘¸ì‹œ ì•Œë¦¼ ë°œì†¡ í•¨ìˆ˜ (êµ¬ì¡°í™”ëœ data í˜ì´ë¡œë“œ + ì ìˆ˜ í•„í„°ë§) ---
def send_fcm_notification(ticker, price, probability_score):
    """DBì˜ min_scoreë¥¼ í™•ì¸í•˜ì—¬ ì¡°ê±´ì— ë§ëŠ” ì‚¬ìš©ìì—ê²Œë§Œ ì•Œë¦¼ì„ ë°œì†¡í•©ë‹ˆë‹¤."""
    
    if not firebase_admin._apps:
        print("ğŸ”” [FCM] Firebase Admin SDKê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•„ ì•Œë¦¼ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
        return

    conn = None
    try:
        conn = get_db_connection()
        cursor = conn.cursor()
        
        # âœ… [ìˆ˜ì • 1] í† í°ê³¼ í•¨ê»˜ 'min_score' ì„¤ì •ê°’ë„ ê°€ì ¸ì˜µë‹ˆë‹¤.
        cursor.execute("SELECT token, min_score FROM fcm_tokens")
        subscribers = cursor.fetchall() 
        
        cursor.close()
        conn.close()

        if not subscribers:
            print("ğŸ”” [FCM] DBì— ë“±ë¡ëœ ì•Œë¦¼ êµ¬ë…ìê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        print(f"ğŸ”” [FCM] ì´ {len(subscribers)}ëª…ì˜ êµ¬ë…ì í™•ì¸. í•„í„°ë§ ë° ë°œì†¡ ì‹œì‘...")
        
        # 1. data í˜ì´ë¡œë“œ êµ¬ì„± (ë™ì¼)
        data_payload = {
            'title': "Danso AI ì‹ í˜¸", 
            'ticker': ticker,
            'price': f"{price:.4f}",
            'probability': str(probability_score)
        }
        
        success_count = 0
        failure_count = 0
        skipped_count = 0 # í•„í„°ë§ëœ íšŸìˆ˜ ì¹´ìš´íŠ¸
        failed_tokens = []

        # âœ… [ìˆ˜ì • 2] í† í°ê³¼ ìµœì†Œ ì ìˆ˜ë¥¼ í•˜ë‚˜ì”© êº¼ë‚´ì„œ í™•ì¸
        for row in subscribers:
            token = row[0]
            # DB ê°’ì´ NULLì´ë©´ 0ì ìœ¼ë¡œ ì²˜ë¦¬ (ëª¨ë‘ ë°›ìŒ)
            user_min_score = row[1] if row[1] is not None else 0 
            
            if not token: continue

            # âœ… [í•µì‹¬ ë¡œì§] ì‹ í˜¸ ì ìˆ˜ê°€ ì‚¬ìš©ìì˜ ì„¤ì • ì ìˆ˜ë³´ë‹¤ ë‚®ìœ¼ë©´ ê±´ë„ˆëœ€
            if probability_score < user_min_score:
                skipped_count += 1
                continue 

            try:
                message = messaging.Message(
                    token=token,
                    data=data_payload, 
                    webpush=messaging.WebpushConfig(
                        headers={'Urgency': 'high'}
                    )
                )
                
                messaging.send(message)
                success_count += 1
                
            except Exception as e:
                # print(f"âŒ [FCM] í† í° ì „ì†¡ ì‹¤íŒ¨: {token[:10]}... (ì´ìœ : {e})") # ë¡œê·¸ ë„ˆë¬´ ë§ìœ¼ë©´ ì£¼ì„ ì²˜ë¦¬
                failure_count += 1
                if "Requested entity was not found" in str(e) or "registration-token-not-registered" in str(e):
                    failed_tokens.append(token)
        
        print(f"âœ… [FCM] ë°œì†¡ ê²°ê³¼: ì„±ê³µ {success_count}ëª…, ì‹¤íŒ¨ {failure_count}ëª…, (ì ìˆ˜ ë¯¸ë‹¬ íŒ¨ìŠ¤: {skipped_count}ëª…)")
        
        # ë§Œë£Œëœ í† í° ì‚­ì œ ë¡œì§ (ë™ì¼)
        if failed_tokens:
            try:
                conn = get_db_connection()
                cursor = conn.cursor()
                cursor.execute("DELETE FROM fcm_tokens WHERE token = ANY(%s)", (failed_tokens,))
                conn.commit()
                cursor.close()
                conn.close()
                print(f"ğŸ§¹ [FCM] ë§Œë£Œëœ í† í° {len(failed_tokens)}ê°œë¥¼ DBì—ì„œ ì‚­ì œí–ˆìŠµë‹ˆë‹¤.")
            except Exception as e:
                print(f"âŒ [FCM] ë§Œë£Œëœ í† í° DB ì‚­ì œ ì‹¤íŒ¨: {e}")

    except Exception as e:
        if conn: conn.close()
        print(f"âŒ [FCM] í‘¸ì‹œ ì•Œë¦¼ ë°œì†¡ ì¤‘ ì¹˜ëª…ì  ì˜¤ë¥˜: {e}")
          
# --- (v13.0) DB ë¡œê·¸ í•¨ìˆ˜ (PostgreSQL ìš©) ---
def log_signal(ticker, price, probability_score=50):
    conn = None
    try:
        conn = get_db_connection()
        cursor = conn.cursor()
        # 8. PostgreSQLìš© INSERT (%s ì‚¬ìš©, ? ëŒ€ì‹ )
        cursor.execute("INSERT INTO signals (ticker, price, time) VALUES (%s, %s, %s)", 
                       (ticker, price, datetime.now()))
        conn.commit()
        cursor.close()
        conn.close()
    except Exception as e:
        if conn: conn.close()
        print(f"âŒ [DB] 'signals' ì €ì¥ ì‹¤íŒ¨: {e}")

def log_recommendation(ticker, price, probability_score=50):
    conn = None
    try:
        conn = get_db_connection()
        cursor = conn.cursor()
        # 9. PostgreSQLìš© INSERT (ON CONFLICT DO NOTHING = IGNORE)
        cursor.execute("""
        INSERT INTO recommendations (ticker, price, time, probability_score) 
        VALUES (%s, %s, %s, %s)
        ON CONFLICT (ticker) DO NOTHING
        """, 
                       (ticker, price, datetime.now(), probability_score))
        conn.commit()
        is_new_rec = cursor.rowcount > 0
        cursor.close()
        conn.close()
        return is_new_rec
    except Exception as e:
        if conn: conn.close()
        print(f"âŒ [DB] 'recommendations' ì €ì¥ ì‹¤íŒ¨: {e}")
        return False

# --- 1ë‹¨ê³„ ë¡œì§: "ì˜¤ëŠ˜ì˜ ê´€ì‹¬ ì¡ì£¼" (v7.2) ---
def find_active_tickers():
    if not POLYGON_API_KEY:
        print(f"-> âŒ [ì‚¬ëƒ¥ê¾¼] 1ë‹¨ê³„ ìŠ¤ìº” ì˜¤ë¥˜: POLYGON_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return set()
        
    print(f"\n[ì‚¬ëƒ¥ê¾¼] 1ë‹¨ê³„: 'Top Gainers' (ì¡°ê±´: ${MAX_PRICE} ë¯¸ë§Œ) ìŠ¤ìº” ì¤‘...")
    
    # âœ… (ìˆ˜ì •) URLì„ ì˜¬ë°”ë¥¸ f-string í˜•ì‹ìœ¼ë¡œ ë³€ê²½
    url = f"https://api.polygon.io/v2/snapshot/locale/us/markets/stocks/gainers?apiKey={POLYGON_API_KEY}"

    tickers_to_watch = set()
    try:
        response = requests.get(url)
        response.raise_for_status() 
        data = response.json()
        if data.get('status') == 'OK':
            for ticker in data.get('tickers', []):
                price = ticker.get('lastTrade', {}).get('p', 999) 
                ticker_symbol = ticker.get('ticker')
                is_price_ok = price <= MAX_PRICE
                if is_price_ok and ticker_symbol:
                    tickers_to_watch.add(ticker_symbol)
                if len(tickers_to_watch) >= TOP_N: break
            print(f"-> [ì‚¬ëƒ¥ê¾¼] 1ë‹¨ê³„ ìŠ¤ìº” ì™„ë£Œ. ì´ {len(tickers_to_watch)}ê°œ ì¢…ëª© í¬ì°©.")
            
    except Exception as e:
        print(f"-> âŒ [ì‚¬ëƒ¥ê¾¼] 1ë‹¨ê³„ ìŠ¤ìº” ì˜¤ë¥˜ (API í‚¤/í•œë„ í™•ì¸): {e}")
        return tickers_to_watch # ì˜ˆì™¸ ë°œìƒ ì‹œ ë°˜í™˜
        
    # âœ… (ì¶”ê°€) ì„±ê³µ ì‹œì—ë„ í•­ìƒ setì„ ë°˜í™˜
    return tickers_to_watch
# --- âœ… [ì¶”ê°€ 2] ì‹œê°„ ë° ê±°ë˜ëŸ‰ ë¶„ì„ í•¨ìˆ˜ ì¶”ê°€ ---

def get_current_session():
    """
    í˜„ì¬ ì‹œê°„ì— ë”°ë¼ ì„¸ì…˜ íƒ€ì…ì„ ë°˜í™˜í•©ë‹ˆë‹¤. (US/Eastern ê¸°ì¤€)
    - premarket: 04:00 ~ 09:30
    - regular: 09:30 ~ 16:00
    - aftermarket: 16:00 ~ 20:00
    """
    try:
        ny_tz = pytz.timezone('US/Eastern')
        now = datetime.now(ny_tz).time()

        # ì‹œê°„ëŒ€ ì„¤ì •
        time_pre_start = datetime.strptime("04:00", "%H:%M").time()
        time_regular_start = datetime.strptime("09:30", "%H:%M").time()
        time_after_start = datetime.strptime("16:00", "%H:%M").time()
        time_market_close = datetime.strptime("20:00", "%H:%M").time()

        if time_pre_start <= now < time_regular_start:
            return "premarket"  # [ëª¨ë“œ A]
        elif time_regular_start <= now < time_after_start:
            return "regular"    # [ëª¨ë“œ B] (ì—„ê²© ëª¨ë“œ)
        elif time_after_start <= now < time_market_close:
            return "aftermarket" # [ëª¨ë“œ A]
        else:
            return "closed"      # ì¥ ë§ˆê°
    except Exception as e:
        print(f"âš ï¸ [Time Check Error] {e}")
        return "premarket" # ì—ëŸ¬ ì‹œ ê¸°ë³¸ê°’

def calculate_volume_ratio(df):
    """
    í˜„ì¬ ìº”ë“¤ ê±°ë˜ëŸ‰ / ì§ì „ 5ê°œ ìº”ë“¤ í‰ê·  ê±°ë˜ëŸ‰
    """
    try:
        if len(df) < 6: return 1.0
        current_vol = df['volume'].iloc[-1]
        avg_vol_5 = df['volume'].iloc[-6:-1].mean() # ì§ì „ 5ê°œ í‰ê· 
        
        if avg_vol_5 == 0: return 0.0
        
        ratio = current_vol / avg_vol_5
        return round(ratio, 2)
    except:
        return 1.0
    # --- (ì‹ ê·œ) ê³¼ê±° ë°ì´í„° ìŠ¤ëƒ…ìƒ· ê°€ì ¸ì˜¤ê¸° ---
def fetch_initial_data(ticker):
    """
    ìƒˆë¡œìš´ ì¢…ëª© êµ¬ë… ì‹œ, ê³¼ê±° 200ë¶„(ìº”ë“¤) ë°ì´í„°ë¥¼ ì¦‰ì‹œ ë¡œë”©í•˜ì—¬
    52ë¶„ ëŒ€ê¸° ì‹œê°„(Cold Start)ì„ ì—†ì• ê³  ë°”ë¡œ ë¶„ì„ ê°€ëŠ¥í•˜ê²Œ ë§Œë“¦.
    """
    if not POLYGON_API_KEY: return
    
   # [ìˆ˜ì •] ì•ˆì „í•˜ê²Œ ìµœê·¼ 7ì¼(ì¼ì£¼ì¼) ë²”ìœ„ì—ì„œ ìµœì‹  200ê°œë¥¼ ê°€ì ¸ì˜¤ë„ë¡ ì„¤ì •
    # ì£¼ë§/ê³µíœ´ì¼ì´ ê»´ìˆì–´ë„ ë°ì´í„°ê°€ ëŠê¸°ì§€ ì•Šê²Œ í•˜ê¸° ìœ„í•¨
    end_date = datetime.now().strftime('%Y-%m-%d')
    start_date = (datetime.now() - timedelta(days=7)).strftime('%Y-%m-%d')
    
    # âš ï¸ ì¤‘ìš”: ë°˜ë“œì‹œ sort=descì—¬ì•¼ 'ìµœì‹  ë°ì´í„°'ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤! ascë¡œ í•˜ë©´ ì˜›ë‚  ë°ì´í„° ê°€ì ¸ì˜´.
    url = (
        f"https://api.polygon.io/v2/aggs/ticker/{ticker}/range/1/minute/"
        f"{start_date}/{end_date}?adjusted=true&sort=desc&limit=200&apiKey={POLYGON_API_KEY}"
    )
    
    try:
        print(f"â³ [ì´ˆê¸°í™” ì‹œë„] {ticker} ê³¼ê±° ë°ì´í„° ìš”ì²­ ì¤‘...")
        res = requests.get(url, timeout=5)
        data = res.json()
        
        if data.get('status') == 'OK' and data.get('results'):
            results = data['results']
            # Polygon AggsëŠ” ìµœì‹ ìˆœ(desc)ìœ¼ë¡œ ìš”ì²­í–ˆì–´ë„ ë¦¬ìŠ¤íŠ¸ëŠ” ì„ì¼ ìˆ˜ ìˆìœ¼ë‹ˆ ë‹¤ì‹œ ì •ë ¬
            # ë³´í†µ ì˜¤ë¦„ì°¨ìˆœ(ì˜›ë‚  -> ìµœì‹ )ìœ¼ë¡œ DataFrameì„ ë§Œë“¤ì–´ì•¼ í•¨
            results.sort(key=lambda x: x['t']) 
            
            df = pd.DataFrame(results)
            df.rename(columns={'o':'o', 'h':'h', 'l':'l', 'c':'c', 'v':'v', 't':'t'}, inplace=True)
            df['t'] = pd.to_datetime(df['t'], unit='ms')
            df.set_index('t', inplace=True)
            
            # ì „ì—­ ë³€ìˆ˜ì— ì£¼ì…
            ticker_minute_history[ticker] = df
            print(f"âœ… [ì´ˆê¸°í™”] {ticker} ê³¼ê±° ìº”ë“¤ {len(df)}ê°œ ë¡œë”© ì™„ë£Œ. ì¦‰ì‹œ ë¶„ì„ ê°€ëŠ¥.")
        else:
            # ğŸ”¥ ì—¬ê¸°ê°€ í•µì‹¬: ì™œ ì‹¤íŒ¨í–ˆëŠ”ì§€ ë¡œê·¸ ì¶œë ¥
            print(f"âš ï¸ [ë°ì´í„° ì—†ìŒ] {ticker}: Status={data.get('status')}, Count={data.get('count')}, Msg={data.get('message')}")
    except Exception as e:
        print(f"âš ï¸ [ì´ˆê¸°í™” ì‹¤íŒ¨] {ticker}: {e}")

async def handle_msg(msg_data):
    global ticker_minute_history, ticker_tick_history
    
    # --- ì„¤ì •ê°’ ë¡œë“œ (ì™¸ë¶€ ë³€ìˆ˜ë¼ ê°€ì •) ---
    m_fast, m_slow, m_sig = WAE_MACD
    bb_len, bb_std = WAE_BB
    T, K, S = ICHIMOKU_SHORT
    
    TENKAN_COL = f"ITS_{T}"
    KIJUN_COL = f"IKS_{K}"
    SENKOU_A_COL = f"ISA_{T}"
    SENKOU_B_COL = f"ISB_{K}"
    CHIKOU_COL = f"ICS_{K}"
    
    # âœ… [ìˆ˜ì •] ì…ë ¥ ë°ì´í„° íƒ€ì… ì•ˆì „ì„± í™•ë³´
    if isinstance(msg_data, dict):
        msg_list = [msg_data]
    else:
        msg_list = msg_data

    minute_data = []
    
    # 1. ë°ì´í„° ìˆ˜ì‹  ë° ë¶„ë¥˜
    for msg in msg_list:
        ticker = msg.get('sym')
        if not ticker: continue
            
        # (1) ì‹¤ì‹œê°„ í‹± ë°ì´í„° ìˆ˜ì§‘ (ë³´ê°„ìš©)
        if msg.get('ev') == 'T':
            if ticker not in ticker_tick_history:
                ticker_tick_history[ticker] = []
            
            # í•„ìš”í•œ ë°ì´í„°ë§Œ ê²½ëŸ‰í™”í•´ì„œ ì €ì¥
            ticker_tick_history[ticker].append([msg.get('t'), msg.get('p'), msg.get('s')])
            
            # í‹± ë°ì´í„° ë²„í¼ ê´€ë¦¬
            if len(ticker_tick_history[ticker]) > 1000:
                ticker_tick_history[ticker] = ticker_tick_history[ticker][-1000:]
                
        # (2) 1ë¶„ë´‰ ë°ì´í„° ìˆ˜ì§‘
        elif msg.get('ev') == 'AM':
            # ë¡œê·¸ëŠ” í•„ìš”ì‹œ ì£¼ì„ í•´ì œ
            # print(f"-> [ì—”ì§„ v10.0] 1ë¶„ë´‰ ìˆ˜ì‹ : {ticker} @ ${msg.get('c')}")
            minute_data.append(msg)

    # 2. ê° ì¢…ëª©ë³„ ì§€í‘œ ê³„ì‚° ë° ë¶„ì„
    for msg in minute_data:
        ticker = msg.get('sym')
        
        if ticker not in ticker_minute_history:
            ticker_minute_history[ticker] = pd.DataFrame(columns=['o', 'h', 'l', 'c', 'v', 't'])
            ticker_minute_history[ticker].set_index('t', inplace=True)
            
        timestamp = pd.to_datetime(msg.get('s'), unit='ms')
        new_row = {'o': msg.get('o'), 'h': msg.get('h'), 'l': msg.get('l'), 'c': msg.get('c'), 'v': msg.get('v')}
        ticker_minute_history[ticker].loc[timestamp] = new_row
        
        # âœ… [ì¤‘ìš” ìˆ˜ì •] ë°ì´í„° ë³´ê´€ ê°¯ìˆ˜ 60 -> 200ê°œë¡œ ì¦ê°€
        # ì¼ëª©ê· í˜•í‘œ(52), MACD(26) ë“±ì˜ ì„ í–‰ ê³„ì‚°ì„ ìœ„í•´ ë„‰ë„‰í•œ ë°ì´í„° í•„ìš” (NaN ë°©ì§€)
        if len(ticker_minute_history[ticker]) > 200:
            ticker_minute_history[ticker] = ticker_minute_history[ticker].iloc[-200:]
        
        df_raw = ticker_minute_history[ticker].copy() 
        
        # ìµœì†Œ ë°ì´í„° ìš”êµ¬ëŸ‰ ì²´í¬ (ì¼ëª©ê· í˜•í‘œ ì„ í–‰ìŠ¤íŒ¬B ê³„ì‚° ìµœì†Œì¹˜ ê³ ë ¤)
        if len(df_raw) < max(MIN_DATA_REQ, 52): 
            continue

        # 1ë¶„ë´‰ ë¦¬ìƒ˜í”Œë§
        df = df_raw.resample('1min').agg({
            'o': 'first', 'h': 'max', 'l': 'min', 'c': 'last', 'v': 'sum'
        })
        
        # í‹± ë°ì´í„° ê¸°ë°˜ ë³´ê°„ (Interpolation)
        if ticker in ticker_tick_history and len(ticker_tick_history[ticker]) > 0:
            try:
                ticks_df = pd.DataFrame(ticker_tick_history[ticker], columns=['t', 'p', 's'])
                ticks_df['t'] = pd.to_datetime(ticks_df['t'], unit='ms')
                ticks_df.set_index('t', inplace=True)
                
                # í˜„ì¬ ìƒì„± ì¤‘ì¸ ìµœì‹  ë´‰(Last Row) ì—…ë°ì´íŠ¸
                df['c'] = df['c'].combine_first(ticks_df['p'].resample('1min').last())
                df['o'] = df['o'].combine_first(ticks_df['p'].resample('1min').first())
                df['h'] = df['h'].combine_first(ticks_df['p'].resample('1min').max())
                df['l'] = df['l'].combine_first(ticks_df['p'].resample('1min').min())
                df['v'] = df['v'].combine_first(ticks_df['s'].resample('1min').sum())
                
                ticker_tick_history[ticker] = ticker_tick_history[ticker][-200:] # í‹± ë²„í¼ ì •ë¦¬

            except Exception as e:
                print(f"-> [v9.0 í‹± ë³´ê°„ ê²½ê³ ] {ticker}: {e}")
                
        # ê²°ì¸¡ì¹˜ ì²˜ë¦¬
        df.interpolate(method='linear', inplace=True)
        df.ffill(inplace=True)
        df.bfill(inplace=True)

        if len(df) < MIN_DATA_REQ: 
            continue 

        df.rename(columns={'c': 'close', 'h': 'high', 'l': 'low', 'o': 'open', 'v': 'volume'}, inplace=True)
        
        # --- ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚° (pandas_ta) ---
        try:
            df.ta.macd(fast=m_fast, slow=m_slow, signal=m_sig, append=True)
            df.ta.bbands(length=5, std=1.5, append=True)  # WAEìš©
            df.ta.bbands(length=20, std=2.0, append=True) # âœ… Squeeze ê°ì§€ìš© í‘œì¤€ BB
            df.ta.atr(length=WAE_ATR, append=True)
            df.ta.cmf(length=WAE_CMF, append=True) 
            df.ta.obv(append=True)
            df.ta.rsi(length=RSI_LENGTH, append=True) 
            df.ta.ichimoku(tenkan=T, kijun=K, senkou=S, append=True)
        except Exception as e:
            print(f"-> [ì§€í‘œ ê³„ì‚° ì˜¤ë¥˜] {ticker}: {e}")
            continue
        
        # ì»¬ëŸ¼ ì°¾ê¸°
        MACD_COL = next((c for c in df.columns if c.startswith('MACD_')), None)
        BB_UP_COL = next((c for c in df.columns if c.startswith('BBU_')), None)
        BB_LOW_COL= next((c for c in df.columns if c.startswith('BBL_')), None)
        ATR_COL = next((c for c in df.columns if c.startswith('ATRr_')), None) 
        CMF_COL = next((c for c in df.columns if c.startswith('CMF_')), None)
        RSI_COL = next((c for c in df.columns if c.startswith('RSI_')), None)

        senkou_a_cols = [c for c in df.columns if c.startswith('ISA_') or c.startswith('SENKOU_A_')]
        senkou_b_cols = [c for c in df.columns if c.startswith('ISB_') or c.startswith('SENKOU_B_')]
        tenkan_cols   = [c for c in df.columns if c.startswith('ITS_') or c.startswith('TENKAN_')]
        kijun_cols    = [c for c in df.columns if c.startswith('IKS_') or c.startswith('KIJUN_')]
        chikou_cols   = [c for c in df.columns if c.startswith('ICS_') or c.startswith('CHIKOU_')]

        if not (MACD_COL and BB_UP_COL and BB_LOW_COL and ATR_COL and CMF_COL and
                RSI_COL and senkou_a_cols and senkou_b_cols and tenkan_cols and
                kijun_cols and chikou_cols):
            continue 
        
        SENKOU_A_COL = senkou_a_cols[0]; SENKOU_B_COL = senkou_b_cols[0]
        TENKAN_COL   = tenkan_cols[0];   KIJUN_COL    = kijun_cols[0]
        CHIKOU_COL   = chikou_cols[0]
        
        # WAE ì§€í‘œ ê³„ì‚°
        df['t1'] = (df[MACD_COL] - df[MACD_COL].shift(1)) * WAE_SENSITIVITY
        df['e1'] = df[BB_UP_COL] - df[BB_LOW_COL]
        df['deadZone'] = df[ATR_COL] * WAE_ATR_MULT
            
        last = df.iloc[-1]; prev = df.iloc[-2]

        try:
            # ---------------------------------------------------------
            # âœ… [ê°œì„  1] ì¶”ì„¸ ë° ëˆŒë¦¼ëª© ë¶„ì„ ì§€í‘œ (3ì¢… ì„¸íŠ¸)
            # 1. 5ë¶„ ê¸‰ë“±ë¥  (ë‹¨ê¸° ê³¼ì—´ í™•ì¸)
            # 2. ê³ ì  ëŒ€ë¹„ ëˆŒë¦¼í­ (ì¶”ì„¸ ì´íƒˆ í™•ì¸ - FOXX ê±°ë¥´ê¸°ìš©)
            # 3. ì¼ì¼ ìƒìŠ¹ë¥  (ëª¨ë©˜í…€ í™•ì¸)
            # ---------------------------------------------------------
            price_now = df['close'].iloc[-1]
            
            # 1. 5ë¶„ ê¸‰ë“±ë¥  (Pump Strength)
            if len(df) >= 6:
                price_5m_ago = df['close'].iloc[-6] 
                pump_strength_5m = ((price_now - price_5m_ago) / price_5m_ago) * 100
            else:
                pump_strength_5m = 0.0

            # ğŸ”¥ 2. ê³ ì  ëŒ€ë¹„ ëˆŒë¦¼í­ (Pullback from High) - í•µì‹¬!
            # í˜„ì¬ ë°ì´í„°í”„ë ˆì„(ìµœê·¼ 200ë¶„) ë‚´ì—ì„œì˜ ìµœê³ ê°€ ê¸°ì¤€
            day_high = df['high'].max()
            if day_high > 0:
                pullback_from_high = ((day_high - price_now) / day_high) * 100
            else:
                pullback_from_high = 0.0

            # 3. ì¼ì¼ ìƒìŠ¹ë¥  (Daily Change) - ë°ì´í„° ì‹œì‘ê°€ ëŒ€ë¹„
            day_open = df['open'].iloc[0]
            if day_open > 0:
                daily_change = ((price_now - day_open) / day_open) * 100
            else:
                daily_change = 0.0

            # ---------------------------------------------------------
            # âœ… [ê°œì„  2] ë³¼ë¦°ì € ë°´ë“œ Squeeze ì •êµí™”
            # ë‹¨ìˆœíˆ í­ì´ ì¢ì€ê²Œ ì•„ë‹ˆë¼, 'í‰ì†Œë³´ë‹¤' ì¢ì€ì§€ë¥¼ ë¹„êµ
            # ---------------------------------------------------------
            bb_upper = df[BB_UP_COL].iloc[-1]
            bb_lower = df[BB_LOW_COL].iloc[-1]
            bb_mid_val = (bb_upper + bb_lower) / 2 if (bb_upper + bb_lower) != 0 else 1
            
            current_width = (bb_upper - bb_lower) / bb_mid_val # í˜„ì¬ ë°´ë“œí­ ë¹„ìœ¨

            # ìµœê·¼ 20ë´‰ í‰ê·  ë°´ë“œí­ ê³„ì‚°
            bb_width_series = (df[BB_UP_COL] - df[BB_LOW_COL]) / ((df[BB_UP_COL] + df[BB_LOW_COL]) / 2)
            avg_width_20 = bb_width_series.rolling(20).mean().iloc[-1]
            
            # í˜„ì¬ í­ì´ í‰ê· ë³´ë‹¤ ì‘ìœ¼ë©´ 'ìˆ˜ì¶•(Squeeze)' ìƒíƒœ
            is_squeezed = current_width < avg_width_20

            # ATR(ë³€ë™ì„±) ì¶•ì†Œ í™•ì¸ (ë³´ì¡° ì§€í‘œ)
            atr_now = df[ATR_COL].iloc[-1]
            atr_avg = df[ATR_COL].iloc[-6:-1].mean()
            is_volatility_shrinking = (atr_now < atr_avg) or is_squeezed

            # ---------------------------------------------------------
            # âœ… [ê°œì„  3] ê±°ë˜ëŸ‰ ê°€ë­„ (Volume Dry-up)
            # ---------------------------------------------------------
            curr_vol = df['volume'].iloc[-1]
            avg_vol_5 = df['volume'].iloc[-6:-1].mean()
            if avg_vol_5 == 0: avg_vol_5 = 1
            
            is_volume_dry = curr_vol < (avg_vol_5 * 0.7) # í‰ì†Œì˜ 70% ìˆ˜ì¤€

            # --- ê¸°ë³¸ ì¡°ê±´ ì •ì˜ ---
            cond_wae_momentum = (last['t1'] > last['e1']) and (last['t1'] > last['deadZone'])
            cond_volume = (last[CMF_COL] > 0) and (last['OBV'] > prev['OBV'])
            cond_rsi = (WAE_RSI_RANGE[0] < last[RSI_COL] < WAE_RSI_RANGE[1])

            # --- ì¼ëª©ê· í˜•í‘œ ì¡°ê±´ ---
            # ì¤‘ìš”: í˜„ì¬ ìº”ë“¤ê³¼ ë¹„êµí•  êµ¬ë¦„ëŒ€ëŠ” K(26)ê°œ ì „ì˜ êµ¬ë¦„ëŒ€ ê°’ì„ (pandas_ta êµ¬ì¡°ìƒ)
            idx_cloud = -K if len(df) > K else -1
            cloud_a_current = df[SENKOU_A_COL].iloc[idx_cloud]
            cloud_b_current = df[SENKOU_B_COL].iloc[idx_cloud]
            
            cloud_top = max(cloud_a_current, cloud_b_current)
            is_above_cloud = last['close'] > cloud_top
            tk_cross_bullish = (prev[TENKAN_COL] < prev[KIJUN_COL]) and (last[TENKAN_COL] > last[KIJUN_COL])
            cond_ichimoku_trend = is_above_cloud and tk_cross_bullish
            
            # êµ¬ë¦„ëŒ€ ë‘ê»˜ ë° ì´ê²©ë„
            cloud_thickness = abs(cloud_a_current - cloud_b_current) / last['close'] * 100
            dist_bull = (last['close'] - cloud_top) / last['close'] * 100
            cond_cloud_shape = (cloud_thickness >= CLOUD_THICKNESS) and (0 <= dist_bull <= CLOUD_PROXIMITY) 

            # í›„í–‰ìŠ¤íŒ¬ (26ë´‰ ì „ ì£¼ê°€ë³´ë‹¤ ë†’ì•„ì•¼ í•¨)
            price_K_ago = df['close'].iloc[idx_cloud]
            cond_chikou = last[CHIKOU_COL] > price_K_ago

            # --- ìµœì¢… íŠ¸ë¦¬ê±° ì¡°í•© ---
            
            # A. WAE í­ë°œ (ê°•ë ¥ ë§¤ìˆ˜)
            engine_1_pass = (cond_wae_momentum and cond_rsi)
            
            # B. ì •ì„ ì…‹ì—… (êµ¬ë¦„ëŒ€ ìœ„ + ê±°ë˜ëŸ‰ ë°›ì³ì¤Œ + ëª¨ì–‘ ì¢‹ìŒ)
            engine_2_pass = (cond_cloud_shape and cond_volume and cond_rsi)
            
            # C. [ì‹ ê·œ] ë°œì‚° ì „ì¡° (Pre-Breakout)
            # ì¡°ê±´: ìˆ˜ì¶• ìƒíƒœ + ê±°ë˜ëŸ‰ ë§ë¦„ + êµ¬ë¦„ëŒ€ ìœ„ + (ì¤‘ìš”) ì•„ì§ ê¸‰ë“± ì•ˆí•¨(3% ë¯¸ë§Œ)
            cond_pre_breakout = (is_volatility_shrinking and is_volume_dry and is_above_cloud and pump_strength_5m < 3.0)

            if engine_1_pass or engine_2_pass or cond_pre_breakout:
                
                # ì¶”ê°€ ì •ë³´ ê³„ì‚°
                current_session = get_current_session() # ì™¸ë¶€ í•¨ìˆ˜
                if current_session == "closed": pass 

                vol_ratio = calculate_volume_ratio(df) # ì™¸ë¶€ í•¨ìˆ˜

                # ì „ëµ íƒ€ì… ê²°ì •
                if engine_1_pass: strat_type = "Explosion (WAE)"
                elif cond_pre_breakout: strat_type = "Pre-Breakout (Squeeze)"
                else: strat_type = "Standard Setup"

                conditions_data = {
                    "session_type": current_session,
                    "strategy_type": strat_type,        # ì „ëµ ìœ í˜• ë¡œê¹…
                    "volume_ratio": vol_ratio,
                    "pump_strength_5m": float(round(pump_strength_5m, 2)),
                    "pullback_from_high": float(round(pullback_from_high, 2)), # ì¶”ê°€ë¨
                    "daily_change": float(round(daily_change, 2)),             # ì¶”ê°€ë¨
                    "bb_width_ratio": float(round(current_width / avg_width_20, 2)), # í‰ê·  ëŒ€ë¹„ ë¹„ìœ¨ (1.0 ë¯¸ë§Œì´ë©´ ìˆ˜ì¶•)
                    "is_volume_dry": bool(is_volume_dry),
                    "engine_1_pass": bool(engine_1_pass),
                    "engine_2_pass": bool(engine_2_pass),
                    "pre_breakout": bool(cond_pre_breakout),
                    "rsi_value": float(round(last[RSI_COL], 2)),
                    "cmf_value": float(round(last[CMF_COL], 2)),
                    "cloud_distance_percent": float(round(dist_bull, 2))
                }
                
                # AI íŒë‹¨ ìš”ì²­
                probability_score = await get_gemini_probability(ticker, conditions_data)
                
                print(f"ğŸ’¡ [{strat_type}] {ticker} @ ${last['close']:.4f} | AI: {probability_score}% | Pump: {pump_strength_5m:.1f}%")
                
                is_new_rec = log_recommendation(ticker, float(last['close']), probability_score)
                
                if is_new_rec: 
                    send_discord_alert(ticker, float(last['close']), "recommendation", probability_score)
                    send_fcm_notification(ticker, float(last['close']), probability_score)
            
            else:
                pass
                
        except Exception as e:
            # ì—ëŸ¬ ë¼ì¸ ë²ˆí˜¸ê¹Œì§€ ì¶œë ¥í•˜ì—¬ ë””ë²„ê¹… ìš©ì´í•˜ê²Œ í•¨
            import traceback
            print(f"-> âŒ [ì—”ì§„ CRASH] {ticker} ({e.__traceback__.tb_lineno} line): {e}") 
            pass

# --- (v7.2) ìˆ˜ì‹  ì—”ì§„ ---
async def websocket_engine(websocket):
    try:
        async for message in websocket:
            try:
                data_list = json.loads(message)
                await handle_msg(data_list) 
            except Exception as e:
                print(f"-> âŒ [v9.0 ìˆ˜ì‹  ì—”ì§„ CRASH] 'handle_msg' í˜¸ì¶œ ì‹¤íŒ¨: {e}")
                
    except websockets.exceptions.ConnectionClosed as e:
        print(f"-> âŒ [ì—”ì§„ v9.0] ì›¹ì†Œì¼“ ì—°ê²° ì¢…ë£Œ: {e.reason}") 
    except Exception as e:
        print(f"-> âŒ [ì—”ì§„ v9.0] ì›¹ì†Œì¼“ ì˜¤ë¥˜: {e}")

# --- (v16.2) íŠœë‹: 3ë¶„ë§ˆë‹¤ 'ì‚¬ëƒ¥ê¾¼' ì‹¤í–‰ (API í•œë„ ë³µê·€) ---
async def periodic_scanner(websocket):
    current_subscriptions = set() 
    
    while True:
        try:
            print(f"\n[ì‚¬ëƒ¥ê¾¼] (v16.2) 3ë¶„ ì£¼ê¸° ì‹œì‘. 'ì‹ í˜¸ í”¼ë“œ' (signals, recommendations) DBë¥¼ ì²­ì†Œí•©ë‹ˆë‹¤...")
            conn = get_db_connection()
            cursor = conn.cursor()
            # 10. PostgreSQLì€ TRUNCATEê°€ ë” ë¹ ë¦„ (DELETEë„ ì‘ë™ì€ í•¨)
            cursor.execute("TRUNCATE TABLE signals")
            cursor.execute("TRUNCATE TABLE recommendations")
            conn.commit()
            cursor.close()
            conn.close()
            print("-> [ì‚¬ëƒ¥ê¾¼] DB ì²­ì†Œ ì™„ë£Œ.")
        except Exception as e:
            print(f"-> âŒ [ì‚¬ëƒ¥ê¾¼] DB ì²­ì†Œ ì‹¤íŒ¨: {e}")
            
        new_tickers = find_active_tickers() 
        tickers_to_add = new_tickers - current_subscriptions
        tickers_to_remove = current_subscriptions - new_tickers
        
        try:
            if tickers_to_add:
                print(f"[ì‚¬ëƒ¥ê¾¼] {len(tickers_to_add)}ê°œ ì‹ ê·œ ì¢…ëª© (1ë¶„ë´‰+ê±°ë˜) 1ê°œì”© êµ¬ë… ì‹œì‘: {tickers_to_add}")
                for ticker in tickers_to_add:
                    params_str = f"AM.{ticker},T.{ticker}"
                    sub_payload = json.dumps({"action": "subscribe", "params": params_str})
                    await websocket.send(sub_payload)
                    # 2. ğŸ”¥ [ì¶”ê°€] ê³¼ê±° ë°ì´í„° ì¦‰ì‹œ ë¡œë”© (52ë¶„ ëŒ€ê¸° ì‹œê°„ ì‚­ì œ)
                    # ì´ í•¨ìˆ˜ê°€ ì‹¤í–‰ë˜ë©´ ì¦‰ì‹œ ticker_minute_historyì— 200ê°œ ë´‰ì´ ì±„ì›Œì§
                    fetch_initial_data(ticker)
                    await asyncio.sleep(0.1)
                print("[ì‚¬ëƒ¥ê¾¼] ì‹ ê·œ êµ¬ë… ì™„ë£Œ.")
                
            if tickers_to_remove:
                print(f"[ì‚¬ëƒ¥ê¾¼] {len(tickers_to_remove)}ê°œ ì‹ì€ ì¢…ëª© êµ¬ë… í•´ì§€: {tickers_to_remove}")
                for ticker in tickers_to_remove:
                    params_str = f"AM.{ticker},T.{ticker}"
                    unsub_payload = json.dumps({"action": "unsubscribe", "params": params_str})
                    await websocket.send(unsub_payload)
                    await asyncio.sleep(0.1)
                print("[ì‚¬ëƒ¥ê¾¼] êµ¬ë… í•´ì§€ ì™„ë£Œ.")
                
        except websockets.exceptions.ConnectionClosed:
             print("-> âŒ [ì‚¬ëƒ¥ê¾¼] êµ¬ë…/í•´ì§€ ì‹¤íŒ¨: ì›¹ì†Œì¼“ ì—°ê²°ì´ ì´ë¯¸ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. (ì¬ì—°ê²° ì‹œë„)")
             raise
        except Exception as e:
            print(f"-> âŒ [ì‚¬ëƒ¥ê¾¼] êµ¬ë…/í•´ì§€ ì‹¤íŒ¨: {e}")
            
        current_subscriptions = new_tickers
        
        status_tickers_list = []
        for ticker in current_subscriptions:
            status_tickers_list.append({"ticker": ticker, "is_new": ticker in tickers_to_add})
        status_data = {
            'last_scan_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            'watching_count': len(current_subscriptions),
            'watching_tickers': status_tickers_list
        }
        try:
            status_json_string = json.dumps(status_data)
            conn = get_db_connection()
            cursor = conn.cursor()
            # 11. PostgreSQLìš© INSERT (ON CONFLICT DO UPDATE)
            cursor.execute("""
            INSERT INTO status (key, value, last_updated) 
            VALUES (%s, %s, %s)
            ON CONFLICT (key) DO UPDATE SET
                value = EXCLUDED.value,
                last_updated = EXCLUDED.last_updated
            """,
                           ('status_data', status_json_string, datetime.now()))
            conn.commit()
            cursor.close()
            conn.close()
        except Exception as e:
            print(f"âŒ [DB] 'status' ì €ì¥ ì‹¤íŒ¨: {e}")
            
        # âœ… (íŠœë‹ 1) 7ë¶„(420ì´ˆ) -> 3ë¶„(180ì´ˆ)ë¡œ ë³€ê²½
        # API í•œë„ ë° ì„œë²„ ë¶€í•˜ì— ì£¼ì˜í•´ì•¼ í•©ë‹ˆë‹¤.
        print(f"\n[ì‚¬ëƒ¥ê¾¼] 3ë¶„(180ì´ˆ) í›„ ë‹¤ìŒ ìŠ¤ìº”ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
        await asyncio.sleep(180)

# --- (v8.1) "ìˆ˜ë™ Keepalive" ë¡œë´‡ ---
async def manual_keepalive(websocket):
    try:
        while True:
            await websocket.ping()
            print("-> [Keepalive] Ping ì „ì†¡ (ì—°ê²° ìœ ì§€)")
            await asyncio.sleep(20)
    except websockets.exceptions.ConnectionClosed:
        print("-> [Keepalive] ì—°ê²° ì¢…ë£Œë¨. Ping ì¤‘ë‹¨.")
    except Exception as e:
        print(f"-> âŒ [Keepalive] í•‘ ì „ì†¡ ì¤‘ ì˜¤ë¥˜: {e}")

# --- ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜ (v9.0 - ìë™ ì¬ì—°ê²°) ---
async def main():
    if not POLYGON_API_KEY:
        print("âŒ [ë©”ì¸] POLYGON_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ìŠ¤ìºë„ˆë¥¼ ì‹œì‘í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    if not DATABASE_URL:
        print("âŒ [ë©”ì¸] DATABASE_URLì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ìŠ¤ìºë„ˆë¥¼ ì‹œì‘í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    # Vertex AIìš© í‚¤ í™•ì¸
    if not GEMINI_API_KEY:
        print("âŒ [ë©”ì¸] GEMINI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ìŠ¤ìºë„ˆë¥¼ ì‹œì‘í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    if not GCP_PROJECT_ID or "YOUR_PROJECT_ID" in GCP_PROJECT_ID:
        print("âŒ [ë©”ì¸] GCP_PROJECT_IDê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ìŠ¤ìºë„ˆë¥¼ ì‹œì‘í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # âœ… (ìˆ˜ì •) Firebase Admin SDK í‚¤ í™•ì¸
    if not FIREBASE_ADMIN_SDK_JSON_STR:
        print("âš ï¸ [ë©”ì¸] FIREBASE_ADMIN_SDK_JSONì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. FCM í‘¸ì‹œ ì•Œë¦¼ì´ ë¹„í™œì„±í™”ë©ë‹ˆë‹¤.")


    # âœ… (íŠœë‹) ë²„ì „ ì •ë³´ ìˆ˜ì •
    print("ìŠ¤ìºë„ˆ V16.7 (FCM-Admin SDK)ì„ ì‹œì‘í•©ë‹ˆë‹¤...") 
    uri = "wss://socket.polygon.io/stocks"
    
    while True:
        try:
            async with websockets.connect(uri, ping_interval=None, ping_timeout=300) as websocket:
                print(f"[ë©”ì¸] ì›¹ì†Œì¼“ {uri} ì—°ê²° ì„±ê³µ.")
                
                response = await websocket.recv()
                print(f"[ë©”ì¸] ì—°ê²° ì‘ë‹µ: {response}")
                if '"status":"connected"' not in str(response):
                     print("-> âŒ [ë©”ì¸] ë¹„ì •ìƒ ì—°ê²° ì‘ë‹µ. 10ì´ˆ í›„ ì¬ì‹œë„...")
                     await asyncio.sleep(10)
                     continue

                # 12. API í‚¤ê°€ Noneì´ ì•„ë‹Œì§€ í™•ì¸ (í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ ì‹¤íŒ¨ ëŒ€ë¹„)
                api_key_to_use = POLYGON_API_KEY or ""
                print(f"[ë©”ì¸] API í‚¤ ({api_key_to_use[:4]}...)ë¡œ 'ìˆ˜ë™ ì¸ì¦'ì„ ì‹œë„í•©ë‹ˆë‹¤...")
                auth_payload = json.dumps({"action": "auth", "params": api_key_to_use})
                await websocket.send(auth_payload)
                
                response = await websocket.recv()
                print(f"[ë©”ì¸] ì¸ì¦ ì‘ë‹µ: {response}")
                
                if '"status":"auth_success"' in str(response):
                    print("-> âœ… [ë©”ì¸] 'ìˆ˜ë™ ì¸ì¦' ì„±ê³µ! 3ê°œ ë¡œë´‡(ì‚¬ëƒ¥ê¾¼, ì—”ì§„, í•‘)ì„ ì‹œì‘í•©ë‹ˆë‹¤.")
                    
                    watcher_task = websocket_engine(websocket) 
                    scanner_task = periodic_scanner(websocket)
                    keepalive_task = manual_keepalive(websocket)
                    
                    await asyncio.gather(watcher_task, scanner_task, keepalive_task)
                else:
                    print("-> âŒ [ë©”ì¸] 'ìˆ˜ë™ ì¸ì¦' ì‹¤íŒ¨. 10ì´ˆ í›„ ì¬ì‹œë„...")
                    await asyncio.sleep(10)
                    continue
                    
        except websockets.exceptions.ConnectionClosed as e:
            print(f"-> âŒ [ë©”ì¸] ì›¹ì†Œì¼“ ì—°ê²°ì´ ì˜ˆê¸°ì¹˜ ì•Šê²Œ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤ ({e.code}). 10ì´ˆ í›„ ì¬ì—°ê²°í•©ë‹ˆë‹¤...")
            await asyncio.sleep(10)
        except Exception as e:
            print(f"-> âŒ [ë©”ì¸] ì¹˜ëª…ì  ì˜¤ë¥˜ ë°œìƒ: {e}. 10ì´ˆ í›„ ì¬ì—°ê²°í•©ë‹ˆë‹¤...")
            await asyncio.sleep(10)

# âœ… 5. __name__ == "__main__" ë¸”ë¡ ìˆ˜ì •
if __name__ == "__main__":
    init_db() 
    init_firebase() # âœ… Firebase ì´ˆê¸°í™” í˜¸ì¶œ ì¶”ê°€
    
    # âœ… [ìˆ˜ì •] 'test' ì¸ìê°€ ìˆëŠ”ì§€ í™•ì¸
    if len(sys.argv) > 1 and sys.argv[1] == 'test':
        print("--- [TEST MODE] ---")
        print("DBì™€ Firebase ì´ˆê¸°í™” ì™„ë£Œ. 3ì´ˆ í›„ í…ŒìŠ¤íŠ¸ ì•Œë¦¼ì„ ë°œì†¡í•©ë‹ˆë‹¤...")
        time.sleep(3) # (ë¡œê·¸ ë³¼ ì‹œê°„)
        
        # í…ŒìŠ¤íŠ¸ ì•Œë¦¼ ê°•ì œ ë°œì†¡
        send_fcm_notification(
            ticker="TEST", 
            price=123.45, 
            probability_score=99
        )
        
        print("--- [TEST MODE] í…ŒìŠ¤íŠ¸ ì™„ë£Œ. ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤. ---")
    
    else:
        # 'test' ì¸ìê°€ ì—†ìœ¼ë©´, (ê¸°ì¡´) ìŠ¤ìºë„ˆë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤.
        try: 
            print("--- [LIVE MODE] ìŠ¤ìºë„ˆë¥¼ ì‹œì‘í•©ë‹ˆë‹¤... ---")
            asyncio.run(main()) # âœ… asyncio ì˜¤íƒ€ ìˆ˜ì •
        except KeyboardInterrupt: 
            print("\n[ë©”ì¸] ì‚¬ìš©ìì— ì˜í•´ í”„ë¡œê·¸ë¨ì´ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")