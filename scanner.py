import asyncio
import websockets 
import requests
import os  # 1. os ì„í¬íŠ¸
import pandas as pd
import pandas_ta as ta
import json
from datetime import datetime
import psycopg2  # 2. sqlite3 ëŒ€ì‹  psycopg2
import time
import httpx 

# --- (v12.0) API í‚¤ ì„¤ì • (ë³´ì•ˆ) ---
# 3. Render í™˜ê²½ ë³€ìˆ˜ì—ì„œ API í‚¤ë¥¼ ì½ì–´ì˜µë‹ˆë‹¤.
POLYGON_API_KEY = os.environ.get('POLYGON_API_KEY')
GEMINI_API_KEY = os.environ.get('GEMINI_API_KEY')
DISCORD_WEBHOOK_URL = os.environ.get('DISCORD_WEBHOOK_URL')

# --- (v9.5) "5ë¶„ ì•ˆì •í™” ì—”ì§„" (í•©ì˜ì ) ---
MAX_PRICE = 10
TOP_N = 50
MIN_DATA_REQ = 6

# --- (v9.5) ì—”ì§„ 1: WAE (5ë¶„) ---
WAE_MACD = (2, 3, 4) 
WAE_SENSITIVITY = 150
WAE_BB = (5, 1.5) 
WAE_ATR = 5 
WAE_ATR_MULT = 1.5
WAE_CMF = 5 
WAE_RSI_RANGE = (45, 75) 
RSI_LENGTH = 5 

# --- (v9.5) ì—”ì§„ 2: ì¼ëª© (5ë¶„) ---
ICHIMOKU_SHORT = (2, 3, 5) 
CLOUD_PROXIMITY = 20.0 
CLOUD_THICKNESS = 0.5
OBV_LOOKBACK = 3 

# --- (v13.0) DB ê²½ë¡œ ì„¤ì • (PostgreSQL ì—°ë™) ---
# 4. Render í™˜ê²½ ë³€ìˆ˜ì—ì„œ PostgreSQL DB ì—°ê²° ì£¼ì†Œë¥¼ ì½ì–´ì˜µë‹ˆë‹¤.
DATABASE_URL = os.environ.get('DATABASE_URL')

def get_db_connection():
    """PostgreSQL DB ì—°ê²°ì„ ìƒì„±í•©ë‹ˆë‹¤."""
    # DATABASE_URLì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ëŠ”ì§€ í™•ì¸
    if not DATABASE_URL:
        raise ValueError("DATABASE_URL í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    conn = psycopg2.connect(DATABASE_URL)
    return conn

ticker_minute_history = {} 
ticker_tick_history = {} 

# --- Gemini API í˜¸ì¶œ í•¨ìˆ˜ (ì´ì „ê³¼ ë™ì¼) ---
async def get_gemini_probability(ticker, conditions_data):
    if not GEMINI_API_KEY:
        print(f"-> [Gemini AI] {ticker}: GEMINI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•„ AI ë¶„ì„ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
        return 50 

    system_prompt = """
You are a specialized quantitative analyst AI for high-speed scalping.
Your task is to evaluate the provided JSON data for a 'buy' signal and return a "probability_score" (0-100) for a short-term price increase (5-30 min).
**Your primary rule is to aggressively penalize overextended signals.**
Many signals fail because they trigger when the price is already too high (overbought).
1.  **Analyze Risk (Most Important):**
    * Look at "rsi_value" and "cloud_distance_percent".
    * If "rsi_value" is high (e.g., > 70) OR "cloud_distance_percent" is large (e.g., > 15%), the signal is **high-risk**.
    * For high-risk signals, assign a **very low probability_score (e.g., 20-40)**, even if other conditions ("engine_1_pass", "engine_2_pass") are true. A good signal at a bad price is a bad signal.
2.  **Analyze Signal Strength (Secondary):**
    * If the signal is **NOT** high-risk, then evaluate its strength.
    * `engine_1_pass (Explosion)` is a strong momentum indicator.
    * `engine_2_pass (Setup)` is a good trend-following indicator.
    * `volume_ok` and `chikou_ok` provide good confirmation.
3.  **Scoring Guideline:**
    * **50 = Neutral.**
    * **20- (High Risk / Trap):** Signal is overextended (High RSI or Cloud Distance). **Strongly avoid.**
    * **60-75 (Good):** A decent signal with low risk.
    * **80+ (Excellent):** A strong signal (e.g., Engine 1 or 2 passed) AND low risk (Low RSI, close to cloud).
You MUST respond ONLY with the specified JSON schema.
"""
    user_prompt = f"""
    Analyze the following signal data for Ticker: {ticker}
    {json.dumps(conditions_data, indent=2)}
    """
    api_url = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key={GEMINI_API_KEY}"
    payload = {
        "contents": [{"parts": [{"text": user_prompt}]}],
        "systemInstruction": {"parts": [{"text": system_prompt}]},
        "generationConfig": {
            "responseMimeType": "application/json",
            "responseSchema": {
                "type": "OBJECT",
                "properties": {
                    "probability_score": {"type": "NUMBER"},
                    "reasoning": {"type": "STRING"}
                },
                "propertyOrdering": ["probability_score", "reasoning"]
            }
        }
    }
    try:
        async with httpx.AsyncClient() as client:
            response = await client.post(api_url, json=payload, timeout=10.0)
            response.raise_for_status()
            result = response.json()
            response_text = result.get('candidates', [{}])[0].get('content', {}).get('parts', [{}])[0].get('text', '{}')
            score_data = json.loads(response_text)
            score = int(score_data.get("probability_score", 50))
            reasoning = score_data.get("reasoning", "No reasoning provided.")
            print(f"-> [Gemini AI] {ticker}: ìƒìŠ¹ í™•ë¥  {score}% (ì´ìœ : {reasoning})")
            return score
    except Exception as e:
        print(f"-> âŒ [Gemini AI] {ticker} ë¶„ì„ ì‹¤íŒ¨: {e}")
        return 50

# --- (v13.0) DB ì´ˆê¸°í™” í•¨ìˆ˜ (PostgreSQL ìš©) ---
def init_db():
    """PostgreSQL DBì™€ í…Œì´ë¸” 4ê°œë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    conn = None
    try:
        # 5. DATABASE_URLì´ ì„¤ì •ë˜ì—ˆëŠ”ì§€ ë¨¼ì € í™•ì¸
        if not DATABASE_URL:
            print("âŒ [DB] DATABASE_URLì´ ì„¤ì •ë˜ì§€ ì•Šì•„ ì´ˆê¸°í™”ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
            return
            
        conn = get_db_connection()
        cursor = conn.cursor()
        
        # 6. PostgreSQLì— ë§ëŠ” í…Œì´ë¸” ìƒì„± (SERIAL = AUTOINCREMENT, TIMESTAMP)
        cursor.execute("""
        CREATE TABLE IF NOT EXISTS status (
            key TEXT PRIMARY KEY, 
            value TEXT NOT NULL, 
            last_updated TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        )
        """)
        cursor.execute("""
        CREATE TABLE IF NOT EXISTS signals (
            id SERIAL PRIMARY KEY, 
            ticker TEXT NOT NULL, 
            price REAL NOT NULL, 
            time TIMESTAMP NOT NULL
        )
        """)
        cursor.execute("""
        CREATE TABLE IF NOT EXISTS recommendations (
            id SERIAL PRIMARY KEY, 
            ticker TEXT NOT NULL UNIQUE, 
            price REAL NOT NULL, 
            time TIMESTAMP NOT NULL, 
            probability_score INTEGER
        )
        """)
        cursor.execute("""
        CREATE TABLE IF NOT EXISTS posts (
            id SERIAL PRIMARY KEY, 
            author TEXT NOT NULL, 
            content TEXT NOT NULL, 
            time TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        )
        """)
        conn.commit()
        
        try:
            # 7. PostgreSQLìš© ALTER TABLE (ì—ëŸ¬ í•¸ë“¤ë§ìœ¼ë¡œ ì²˜ë¦¬)
            cursor.execute("ALTER TABLE recommendations ADD COLUMN probability_score INTEGER")
            conn.commit()
            print("-> [DB] 'recommendations' í…Œì´ë¸”ì— 'probability_score' ì»¬ëŸ¼ ì¶”ê°€ ì‹œë„ ì™„ë£Œ.")
        except psycopg2.Error as e:
            if e.pgcode == '42701': # 'Duplicate Column' ì—ëŸ¬ ì½”ë“œ
                pass # ì»¬ëŸ¼ì´ ì´ë¯¸ ì¡´ì¬í•¨, ì •ìƒ
            else:
                raise # ë‹¤ë¥¸ ì¢…ë¥˜ì˜ ì—ëŸ¬ë¼ë©´ ë‹¤ì‹œ ë°œìƒì‹œí‚´
            
        cursor.close()
        conn.close()
        print(f"âœ… [DB] PostgreSQL í…Œì´ë¸” ì´ˆê¸°í™” ì„±ê³µ.")
    except Exception as e:
        if conn: conn.close()
        print(f"âŒ [DB] PostgreSQL ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")

# --- (v8.0) ì•Œë¦¼/ë¡œê·¸ í•¨ìˆ˜ ---
def send_discord_alert(ticker, price, type="signal", probability_score=50):
    if not DISCORD_WEBHOOK_URL or "YOUR_DISCORD" in DISCORD_WEBHOOK_URL or len(DISCORD_WEBHOOK_URL) < 50:
        print(f"ğŸ”” [ì•Œë¦¼] {ticker} @ ${price} (ë””ìŠ¤ì½”ë“œ URL ë¯¸ì„¤ì •)")
        return
        
    if type == "signal": 
        content = f"ğŸš€ **WAE í­ë°œ ì‹ í˜¸** ğŸš€\n**{ticker}** @ **${price}**\n**AI ìƒìŠ¹ í™•ë¥ : {probability_score}%**"
    else: 
        content = f"ğŸ’¡ **ì •ì„ ì…‹ì—… (ì¶”ì²œ)** ğŸ’¡\n**{ticker}** @ **${price}**\n**AI ìƒìŠ¹ í™•ë¥ : {probability_score}%**"
        
    data = {"content": content}
    try: 
        requests.post(DISCORD_WEBHOOK_URL, json=data)
        print(f"ğŸ”” [ì•Œë¦¼] {ticker} @ ${price} (ë””ìŠ¤ì½”ë“œ ì „ì†¡ ì™„ë£Œ)")
    except Exception as e: 
        print(f"[ì•Œë¦¼ ì˜¤ë¥˜] {ticker} ë””ìŠ¤ì½”ë“œ ì „ì†¡ ì‹¤íŒ¨: {e}")

# --- (v13.0) DB ë¡œê·¸ í•¨ìˆ˜ (PostgreSQL ìš©) ---
def log_signal(ticker, price, probability_score=50):
    conn = None
    try:
        conn = get_db_connection()
        cursor = conn.cursor()
        # 8. PostgreSQLìš© INSERT (%s ì‚¬ìš©, ? ëŒ€ì‹ )
        cursor.execute("INSERT INTO signals (ticker, price, time) VALUES (%s, %s, %s)", 
                       (ticker, price, datetime.now()))
        conn.commit()
        cursor.close()
        conn.close()
    except Exception as e:
        if conn: conn.close()
        print(f"âŒ [DB] 'signals' ì €ì¥ ì‹¤íŒ¨: {e}")

def log_recommendation(ticker, price, probability_score=50):
    conn = None
    try:
        conn = get_db_connection()
        cursor = conn.cursor()
        # 9. PostgreSQLìš© INSERT (ON CONFLICT DO NOTHING = IGNORE)
        cursor.execute("""
        INSERT INTO recommendations (ticker, price, time, probability_score) 
        VALUES (%s, %s, %s, %s)
        ON CONFLICT (ticker) DO NOTHING
        """, 
                       (ticker, price, datetime.now(), probability_score))
        conn.commit()
        is_new_rec = cursor.rowcount > 0
        cursor.close()
        conn.close()
        return is_new_rec
    except Exception as e:
        if conn: conn.close()
        print(f"âŒ [DB] 'recommendations' ì €ì¥ ì‹¤íŒ¨: {e}")
        return False

# --- 1ë‹¨ê³„ ë¡œì§: "ì˜¤ëŠ˜ì˜ ê´€ì‹¬ ì¡ì£¼" (v7.2) ---
def find_active_tickers():
    if not POLYGON_API_KEY:
        print(f"-> âŒ [ì‚¬ëƒ¥ê¾¼] 1ë‹¨ê³„ ìŠ¤ìº” ì˜¤ë¥˜: POLYGON_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return set()
        
    print(f"\n[ì‚¬ëƒ¥ê¾¼] 1ë‹¨ê³„: 'Top Gainers' (ì¡°ê±´: ${MAX_PRICE} ë¯¸ë§Œ) ìŠ¤ìº” ì¤‘...")
    url = f"https://api.polygon.io/v2/snapshot/locale/us/markets/stocks/gainers?apiKey={POLYGON_API_KEY}"
    tickers_to_watch = set()
    try:
        response = requests.get(url)
        response.raise_for_status() 
        data = response.json()
        if data.get('status') == 'OK':
            for ticker in data.get('tickers', []):
                price = ticker.get('lastTrade', {}).get('p', 999) 
                ticker_symbol = ticker.get('ticker')
                is_price_ok = price <= MAX_PRICE
                if is_price_ok and ticker_symbol:
                    tickers_to_watch.add(ticker_symbol)
                if len(tickers_to_watch) >= TOP_N: break
            print(f"-> [ì‚¬ëƒ¥ê¾¼] 1ë‹¨ê³„ ìŠ¤ìº” ì™„ë£Œ. ì´ {len(tickers_to_watch)}ê°œ ì¢…ëª© í¬ì°©.")
            
            return tickers_to_watch
    except Exception as e:
        print(f"-> âŒ [ì‚¬ëƒ¥ê¾¼] 1ë‹¨ê³„ ìŠ¤ìº” ì˜¤ë¥˜ (API í‚¤/í•œë„ í™•ì¸): {e}")
        return tickers_to_watch

# --- 2ë‹¨ê³„ ë¡œì§: "v5.1 ëŠìŠ¨í•œ í†µí•© ì—”ì§„" (5ë¶„) ---
async def handle_msg(msg_list):
    global ticker_minute_history, ticker_tick_history
    m_fast, m_slow, m_sig = WAE_MACD; bb_len, bb_std = WAE_BB
    T, K, S = ICHIMOKU_SHORT
    
    TENKAN_COL = f"ITS_{T}"
    KIJUN_COL = f"IKS_{K}"
    SENKOU_A_COL = f"ISA_{T}"
    SENKOU_B_COL = f"ISB_{K}"
    CHIKOU_COL = f"ICS_{K}"
    
    minute_data = []
    for msg in msg_list:
        ticker = msg.get('sym')
        if not ticker:
            continue
            
        if msg.get('ev') == 'T':
            if ticker not in ticker_tick_history:
                ticker_tick_history[ticker] = []
            ticker_tick_history[ticker].append([msg.get('t'), msg.get('p'), msg.get('s')])
            if len(ticker_tick_history[ticker]) > 1000:
                ticker_tick_history[ticker] = ticker_tick_history[ticker][-1000:]
                
        elif msg.get('ev') == 'AM':
            print(f"-> [ì—”ì§„ v10.0] 1ë¶„ë´‰ ë°ì´í„° ìˆ˜ì‹ : {ticker} @ ${msg.get('c')} (Vol: {msg.get('v')})")
            minute_data.append(msg)

    for msg in minute_data:
        ticker = msg.get('sym')
        
        if ticker not in ticker_minute_history:
            ticker_minute_history[ticker] = pd.DataFrame(columns=['o', 'h', 'l', 'c', 'v', 't'])
            ticker_minute_history[ticker].set_index('t', inplace=True)
            
        timestamp = pd.to_datetime(msg.get('s'), unit='ms')
        new_row = {'o': msg.get('o'), 'h': msg.get('h'), 'l': msg.get('l'), 'c': msg.get('c'), 'v': msg.get('v')}
        ticker_minute_history[ticker].loc[timestamp] = new_row
        
        if len(ticker_minute_history[ticker]) > 60:
            ticker_minute_history[ticker] = ticker_minute_history[ticker].iloc[-60:]
        
        df_raw = ticker_minute_history[ticker].copy() 
        
        if len(df_raw) < MIN_DATA_REQ: continue

        df = df_raw.resample('1min').agg({
            'o': 'first', 'h': 'max', 'l': 'min', 'c': 'last', 'v': 'sum'
        })
        
        if ticker in ticker_tick_history and len(ticker_tick_history[ticker]) > 0:
            try:
                ticks_df = pd.DataFrame(ticker_tick_history[ticker], columns=['t', 'p', 's'])
                ticks_df['t'] = pd.to_datetime(ticks_df['t'], unit='ms')
                ticks_df.set_index('t', inplace=True)
                
                df['c'] = df['c'].combine_first(ticks_df['p'].resample('1min').last())
                df['o'] = df['o'].combine_first(ticks_df['p'].resample('1min').first())
                df['h'] = df['h'].combine_first(ticks_df['p'].resample('1min').max())
                df['l'] = df['l'].combine_first(ticks_df['p'].resample('1min').min())
                df['v'] = df['v'].combine_first(ticks_df['s'].resample('1min').sum())
                
                ticker_tick_history[ticker] = ticker_tick_history[ticker][-100:]

            except Exception as e:
                print(f"-> [v9.0 í‹± ë³´ê°„ ì‹¤íŒ¨] {ticker}: {e}")
                
        df.interpolate(method='linear', inplace=True)
        df.ffill(inplace=True)
        df.bfill(inplace=True)

        if len(df) < MIN_DATA_REQ: 
            continue 

        df.rename(columns={'c': 'close', 'h': 'high', 'l': 'low', 'o': 'open', 'v': 'volume'}, inplace=True)
        
        df.ta.macd(fast=m_fast, slow=m_slow, signal=m_sig, append=True)
        df.ta.bbands(length=bb_len, std=bb_std, append=True)
        df.ta.atr(length=WAE_ATR, append=True)
        df.ta.cmf(length=WAE_CMF, append=True) 
        df.ta.obv(append=True)
        df.ta.rsi(length=RSI_LENGTH, append=True) 
        df.ta.ichimoku(tenkan=T, kijun=K, senkou=S, append=True)
        
        MACD_COL = next((c for c in df.columns if c.startswith('MACD_')), None)
        BB_UP_COL = next((c for c in df.columns if c.startswith('BBU_')), None)
        BB_LOW_COL= next((c for c in df.columns if c.startswith('BBL_')), None)
        ATR_COL = next((c for c in df.columns if c.startswith('ATRr_')), None) 
        CMF_COL = next((c for c in df.columns if c.startswith('CMF_')), None)
        RSI_COL = next((c for c in df.columns if c.startswith('RSI_')), None)

        senkou_a_cols = [c for c in df.columns if c.startswith('ISA_') or c.startswith('SENKOU_A_')]
        senkou_b_cols = [c for c in df.columns if c.startswith('ISB_') or c.startswith('SENKOU_B_')]
        tenkan_cols   = [c for c in df.columns if c.startswith('ITS_') or c.startswith('TENKAN_')]
        kijun_cols    = [c for c in df.columns if c.startswith('IKS_') or c.startswith('KIJUN_')]
        chikou_cols   = [c for c in df.columns if c.startswith('ICS_') or c.startswith('CHIKOU_')]

        if not (MACD_COL and BB_UP_COL and BB_LOW_COL and ATR_COL and CMF_COL and
                RSI_COL and senkou_a_cols and senkou_b_cols and tenkan_cols and
                kijun_cols and chikou_cols):
            continue 
        
        SENKOU_A_COL = senkou_a_cols[0]; SENKOU_B_COL = senkou_b_cols[0]
        TENKAN_COL   = tenkan_cols[0];   KIJUN_COL    = kijun_cols[0]
        CHIKOU_COL   = chikou_cols[0]
        
        df['t1'] = (df[MACD_COL] - df[MACD_COL].shift(1)) * WAE_SENSITIVITY
        df['e1'] = df[BB_UP_COL] - df[BB_LOW_COL]
        df['deadZone'] = df[ATR_COL] * WAE_ATR_MULT
        
        if len(df) < MIN_DATA_REQ: continue 
            
        last = df.iloc[-1]; prev = df.iloc[-2]

        try:
            cond_wae_momentum = (last['t1'] > last['e1']) and (last['t1'] > last['deadZone'])
            cond_volume = (last[CMF_COL] > 0) and (last['OBV'] > prev['OBV'])
            cond_rsi = (WAE_RSI_RANGE[0] < last[RSI_COL] < WAE_RSI_RANGE[1])

            cloud_a_current = df[SENKOU_A_COL].iloc[-K]; cloud_b_current = df[SENKOU_B_COL].iloc[-K]
            cloud_top = max(cloud_a_current, cloud_b_current); 
            is_above_cloud = last['close'] > cloud_top
            tk_cross_bullish = (prev[TENKAN_COL] < prev[KIJUN_COL]) and (last[TENKAN_COL] > last[KIJUN_COL])
            cond_ichimoku_trend = is_above_cloud and tk_cross_bullish
            
            cloud_thickness = abs(cloud_a_current - cloud_b_current) / last['close'] * 100
            dist_bull = (last['close'] - cloud_top) / last['close'] * 100
            cond_cloud_shape = (cloud_thickness >= CLOUD_THICKNESS) and (0 <= dist_bull <= CLOUD_PROXIMITY)

            chikou = last[CHIKOU_COL] 
            price_K_ago = df['close'].iloc[-K] 
            cond_chikou = chikou > price_K_ago

            engine_1_pass = (cond_wae_momentum and cond_rsi)
            engine_2_pass = (cond_cloud_shape and cond_volume and cond_rsi)
            
            if engine_1_pass or engine_2_pass:
                
                conditions_data = {
                    "engine_1_pass (Explosion)": bool(engine_1_pass),
                    "engine_2_pass (Setup)": bool(engine_2_pass),
                    "wae_momentum": bool(cond_wae_momentum),
                    "rsi_ok": bool(cond_rsi),
                    "volume_ok": bool(cond_volume),
                    "cloud_shape_ok (20%)": bool(cond_cloud_shape),
                    "ichimoku_trend_ok": bool(cond_ichimoku_trend),
                    "chikou_ok": bool(cond_chikou),
                    "rsi_value": float(round(last[RSI_COL], 2)),
                    "cmf_value": float(round(last[CMF_COL], 2)),
                    "cloud_distance_percent": float(round(dist_bull, 2))
                }
                
                probability_score = await get_gemini_probability(ticker, conditions_data)
                
                print(f"ğŸ’¡ğŸ’¡ğŸ’¡ [í†µí•© ì—”ì§„ v5.1] {ticker} @ ${last['close']} (AI Score: {probability_score}%) ğŸ’¡ğŸ’¡ğŸ’¡")
                is_new_rec = log_recommendation(ticker, float(last['close']), probability_score)
                if is_new_rec: send_discord_alert(ticker, float(last['close']), "recommendation", probability_score)
            
            else:
                pass
                
        except Exception as e:
            print(f"-> âŒ [ì—”ì§„ CRASH] {ticker} ë¶„ì„ ì¤‘ ì¹˜ëª…ì  ì˜¤ë¥˜: {e}") 
            pass 

# --- (v7.2) ìˆ˜ì‹  ì—”ì§„ ---
async def websocket_engine(websocket):
    try:
        async for message in websocket:
            try:
                data_list = json.loads(message)
                await handle_msg(data_list) 
            except Exception as e:
                print(f"-> âŒ [v9.0 ìˆ˜ì‹  ì—”ì§„ CRASH] 'handle_msg' í˜¸ì¶œ ì‹¤íŒ¨: {e}")
                
    except websockets.exceptions.ConnectionClosed as e:
        print(f"-> âŒ [ì—”ì§„ v9.0] ì›¹ì†Œì¼“ ì—°ê²° ì¢…ë£Œ: {e.reason}") 
    except Exception as e:
        print(f"-> âŒ [ì—”ì§„ v9.0] ì›¹ì†Œì¼“ ì˜¤ë¥˜: {e}")

# --- 3ë¶„ë§ˆë‹¤ 'ì‚¬ëƒ¥ê¾¼' ì‹¤í–‰ (v9.7 ìˆ˜ì •) ---
async def periodic_scanner(websocket):
    current_subscriptions = set() 
    
    while True:
        try:
            print(f"\n[ì‚¬ëƒ¥ê¾¼] (v9.7) 7ë¶„ ì£¼ê¸° ì‹œì‘. 'ì‹ í˜¸ í”¼ë“œ' (signals, recommendations) DBë¥¼ ì²­ì†Œí•©ë‹ˆë‹¤...")
            conn = get_db_connection()
            cursor = conn.cursor()
            # 10. PostgreSQLì€ TRUNCATEê°€ ë” ë¹ ë¦„ (DELETEë„ ì‘ë™ì€ í•¨)
            cursor.execute("TRUNCATE TABLE signals")
            cursor.execute("TRUNCATE TABLE recommendations")
            conn.commit()
            cursor.close()
            conn.close()
            print("-> [ì‚¬ëƒ¥ê¾¼] DB ì²­ì†Œ ì™„ë£Œ.")
        except Exception as e:
            print(f"-> âŒ [ì‚¬ëƒ¥ê¾¼] DB ì²­ì†Œ ì‹¤íŒ¨: {e}")
            
        new_tickers = find_active_tickers() 
        tickers_to_add = new_tickers - current_subscriptions
        tickers_to_remove = current_subscriptions - new_tickers
        
        try:
            if tickers_to_add:
                print(f"[ì‚¬ëƒ¥ê¾¼] {len(tickers_to_add)}ê°œ ì‹ ê·œ ì¢…ëª© (1ë¶„ë´‰+ê±°ë˜) 1ê°œì”© êµ¬ë… ì‹œì‘: {tickers_to_add}")
                for ticker in tickers_to_add:
                    params_str = f"AM.{ticker},T.{ticker}"
                    sub_payload = json.dumps({"action": "subscribe", "params": params_str})
                    await websocket.send(sub_payload)
                    await asyncio.sleep(0.1)
                print("[ì‚¬ëƒ¥ê¾¼] ì‹ ê·œ êµ¬ë… ì™„ë£Œ.")
                
            if tickers_to_remove:
                print(f"[ì‚¬ëƒ¥ê¾¼] {len(tickers_to_remove)}ê°œ ì‹ì€ ì¢…ëª© êµ¬ë… í•´ì§€: {tickers_to_remove}")
                for ticker in tickers_to_remove:
                    params_str = f"AM.{ticker},T.{ticker}"
                    unsub_payload = json.dumps({"action": "unsubscribe", "params": params_str})
                    await websocket.send(unsub_payload)
                    await asyncio.sleep(0.1)
                print("[ì‚¬ëƒ¥ê¾¼] êµ¬ë… í•´ì§€ ì™„ë£Œ.")
                
        except websockets.exceptions.ConnectionClosed:
             print("-> âŒ [ì‚¬ëƒ¥ê¾¼] êµ¬ë…/í•´ì§€ ì‹¤íŒ¨: ì›¹ì†Œì¼“ ì—°ê²°ì´ ì´ë¯¸ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. (ì¬ì—°ê²° ì‹œë„)")
             raise
        except Exception as e:
            print(f"-> âŒ [ì‚¬ëƒ¥ê¾¼] êµ¬ë…/í•´ì§€ ì‹¤íŒ¨: {e}")
            
        current_subscriptions = new_tickers
        
        status_tickers_list = []
        for ticker in current_subscriptions:
            status_tickers_list.append({"ticker": ticker, "is_new": ticker in tickers_to_add})
        status_data = {
            'last_scan_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            'watching_count': len(current_subscriptions),
            'watching_tickers': status_tickers_list
        }
        try:
            status_json_string = json.dumps(status_data)
            conn = get_db_connection()
            cursor = conn.cursor()
            # 11. PostgreSQLìš© INSERT (ON CONFLICT DO UPDATE)
            cursor.execute("""
            INSERT INTO status (key, value, last_updated) 
            VALUES (%s, %s, %s)
            ON CONFLICT (key) DO UPDATE SET
                value = EXCLUDED.value,
                last_updated = EXCLUDED.last_updated
            """,
                           ('status_data', status_json_string, datetime.now()))
            conn.commit()
            cursor.close()
            conn.close()
        except Exception as e:
            print(f"âŒ [DB] 'status' ì €ì¥ ì‹¤íŒ¨: {e}")
            
        print(f"\n[ì‚¬ëƒ¥ê¾¼] 7ë¶„(420ì´ˆ) í›„ ë‹¤ìŒ ìŠ¤ìº”ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
        await asyncio.sleep(420) 

# --- (v8.1) "ìˆ˜ë™ Keepalive" ë¡œë´‡ ---
async def manual_keepalive(websocket):
    try:
        while True:
            await websocket.ping()
            print("-> [Keepalive] Ping ì „ì†¡ (ì—°ê²° ìœ ì§€)")
            await asyncio.sleep(20)
    except websockets.exceptions.ConnectionClosed:
        print("-> [Keepalive] ì—°ê²° ì¢…ë£Œë¨. Ping ì¤‘ë‹¨.")
    except Exception as e:
        print(f"-> âŒ [Keepalive] í•‘ ì „ì†¡ ì¤‘ ì˜¤ë¥˜: {e}")

# --- ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜ (v9.0 - ìë™ ì¬ì—°ê²°) ---
async def main():
    if not POLYGON_API_KEY:
        print("âŒ [ë©”ì¸] POLYGON_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ìŠ¤ìºë„ˆë¥¼ ì‹œì‘í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    if not DATABASE_URL:
        print("âŒ [ë©”ì¸] DATABASE_URLì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ìŠ¤ìºë„ˆë¥¼ ì‹œì‘í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    print("ìŠ¤ìºë„ˆ V13.0 (PostgreSQL)ì„ ì‹œì‘í•©ë‹ˆë‹¤...") 
    uri = "wss://socket.polygon.io/stocks"
    
    while True:
        try:
            async with websockets.connect(uri, ping_interval=None, ping_timeout=300) as websocket:
                print(f"[ë©”ì¸] ì›¹ì†Œì¼“ {uri} ì—°ê²° ì„±ê³µ.")
                
                response = await websocket.recv()
                print(f"[ë©”ì¸] ì—°ê²° ì‘ë‹µ: {response}")
                if '"status":"connected"' not in str(response):
                     print("-> âŒ [ë©”ì¸] ë¹„ì •ìƒ ì—°ê²° ì‘ë‹µ. 10ì´ˆ í›„ ì¬ì‹œë„...")
                     await asyncio.sleep(10)
                     continue

                # 12. API í‚¤ê°€ Noneì´ ì•„ë‹Œì§€ í™•ì¸ (í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ ì‹¤íŒ¨ ëŒ€ë¹„)
                api_key_to_use = POLYGON_API_KEY or ""
                print(f"[ë©”ì¸] API í‚¤ ({api_key_to_use[:4]}...)ë¡œ 'ìˆ˜ë™ ì¸ì¦'ì„ ì‹œë„í•©ë‹ˆë‹¤...")
                auth_payload = json.dumps({"action": "auth", "params": api_key_to_use})
                await websocket.send(auth_payload)
                
                response = await websocket.recv()
                print(f"[ë©”ì¸] ì¸ì¦ ì‘ë‹µ: {response}")
                
                if '"status":"auth_success"' in str(response):
                    print("-> âœ… [ë©”ì¸] 'ìˆ˜ë™ ì¸ì¦' ì„±ê³µ! 3ê°œ ë¡œë´‡(ì‚¬ëƒ¥ê¾¼, ì—”ì§„, í•‘)ì„ ì‹œì‘í•©ë‹ˆë‹¤.")
                    
                    watcher_task = websocket_engine(websocket) 
                    scanner_task = periodic_scanner(websocket)
                    keepalive_task = manual_keepalive(websocket)
                    
                    await asyncio.gather(watcher_task, scanner_task, keepalive_task)
                else:
                    print("-> âŒ [ë©”ì¸] 'ìˆ˜ë™ ì¸ì¦' ì‹¤íŒ¨. 10ì´ˆ í›„ ì¬ì‹œë„...")
                    await asyncio.sleep(10)
                    continue
                    
        except websockets.exceptions.ConnectionClosed as e:
            print(f"-> âŒ [ë©”ì¸] ì›¹ì†Œì¼“ ì—°ê²°ì´ ì˜ˆê¸°ì¹˜ ì•Šê²Œ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤ ({e.code}). 10ì´ˆ í›„ ì¬ì—°ê²°í•©ë‹ˆë‹¤...")
            await asyncio.sleep(10)
        except Exception as e:
            print(f"-> âŒ [ë©”ì¸] ì¹˜ëª…ì  ì˜¤ë¥˜ ë°œìƒ: {e}. 10ì´ˆ í›„ ì¬ì—°ê²°í•©ë‹ˆë‹¤...")
            await asyncio.sleep(10)

if __name__ == "__main__":
    init_db() 
    try: 
        asyncio.run(main())
    except KeyboardInterrupt: 
        print("\n[ë©”ì¸] ì‚¬ìš©ìì— ì˜í•´ í”„ë¡œê·¸ë¨ì´ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")