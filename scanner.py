import asyncio
import websockets
import requests
import os
import pandas as pd
import pandas_ta as ta
import json
from datetime import datetime
import psycopg2
import time
import httpx
from pywebpush import webpush, WebPushException

# --- (v12.0) API í‚¤ ì„¤ì • (ë³´ì•ˆ) ---
POLYGON_API_KEY = os.environ.get('POLYGON_API_KEY')
GEMINI_API_KEY = os.environ.get('GEMINI_API_KEY')
DISCORD_WEBHOOK_URL = os.environ.get('DISCORD_WEBHOOK_URL')

# --- (v15.3) Vertex AI ì„¤ì • (us-central1 ë³µê·€) ---
GCP_PROJECT_ID = "gen-lang-client-0379169283"
GCP_REGION = "us-central1"

# --- âœ… Firebase VAPID í‚¤ (FCM ë°œì†¡ìš©) ---
VAPID_PRIVATE_KEY = os.environ.get('VAPID_PRIVATE_KEY')
VAPID_EMAIL = "mailto:cbvkqtm98@gmail.com"

# --- (v9.5) "5ë¶„ ì•ˆì •í™” ì—”ì§„" (í•©ì˜ì ) ---
MAX_PRICE = 10
TOP_N = 50
MIN_DATA_REQ = 6

# --- (v9.5) ì—”ì§„ 1: WAE (5ë¶„) ---
WAE_MACD = (2, 3, 4)
WAE_SENSITIVITY = 150
WAE_BB = (5, 1.5)
WAE_ATR = 5
WAE_ATR_MULT = 1.5
WAE_CMF = 5
WAE_RSI_RANGE = (45, 75)
RSI_LENGTH = 5

# --- (v9.5) ì—”ì§„ 2: ì¼ëª© (5ë¶„) ---
ICHIMOKU_SHORT = (2, 3, 5)
CLOUD_PROXIMITY = 20.0
CLOUD_THICKNESS = 0.5
OBV_LOOKBACK = 3

# --- (v13.0) DB ê²½ë¡œ ì„¤ì • (PostgreSQL ì—°ë™) ---
DATABASE_URL = os.environ.get('DATABASE_URL')

def get_db_connection():
    """PostgreSQL DB ì—°ê²°ì„ ìƒì„±í•©ë‹ˆë‹¤."""
    if not DATABASE_URL:
        raise ValueError("DATABASE_URL í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    conn = psycopg2.connect(DATABASE_URL)
    return conn

ticker_minute_history = {}
ticker_tick_history = {}

# --- ğŸ”½ [ìˆ˜ì •ë¨] Gemini API í˜¸ì¶œ í•¨ìˆ˜ ğŸ”½ ---
async def get_gemini_probability(ticker, conditions_data):
    if not GEMINI_API_KEY:
        print(f"-> [Gemini AI] {ticker}: GEMINI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•„ AI ë¶„ì„ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
        return 50
    if not GCP_PROJECT_ID or "YOUR_PROJECT_ID" in GCP_PROJECT_ID:
        print(f"-> [Gemini AI] {ticker}: GCP_PROJECT_IDê°€ ì„¤ì •ë˜ì§€ ì•Šì•„ AI ë¶„ì„ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
        return 50

    system_prompt = """
You are a specialized quantitative analyst AI for high-speed scalping.
Your task is to evaluate the provided JSON data for a 'buy' signal and return a "probability_score" (0-100) for a short-term price increase (5-30 min).
**Your primary rule is to aggressively penalize overextended signals.**
Many signals fail because they trigger when the price is already too high (overbought).
1.  **Analyze Risk (Most Important):**
    * Look at "rsi_value" and "cloud_distance_percent".
    * If "rsi_value" is high (e.g., > 70) OR "cloud_distance_percent" is large (e.g., > 15%), the signal is **high-risk**.
    * For high-risk signals, assign a **very low probability_score (e.g., 20-40)**, even if other conditions ("engine_1_pass", "engine_2_pass") are true. A good signal at a bad price is a bad signal.
2.  **Analyze Signal Strength (Secondary):**
    * If the signal is **NOT** high-risk, then evaluate its strength.
    * `engine_1_pass (Explosion)` is a strong momentum indicator.
    * `engine_2_pass (Setup)` is a good trend-following indicator.
    * `volume_ok` and `chikou_ok` provide good confirmation.
3.  **Scoring Guideline:**
    * **50 = Neutral.**
    * **20- (High Risk / Trap):** Signal is overextended (High RSI or Cloud Distance). **Strongly avoid.**
    * **60-75 (Good):** A decent signal with low risk.
    * **80+ (Excellent):** A strong signal (e.g., Engine 1 or 2 passed) AND low risk (Low RSI, close to cloud).
You MUST respond ONLY with the specified JSON schema, without any markdown code blocks.
"""
    user_prompt = f"""
    Analyze the following signal data for Ticker: {ticker}
    {json.dumps(conditions_data, indent=2)}
    """

    api_url = (
        f"https://{GCP_REGION}-aiplatform.googleapis.com/v1/projects/{GCP_PROJECT_ID}"
        f"/locations/{GCP_REGION}/publishers/google/models/gemini-2.5-flash-lite:generateContent"
    )
    combined_prompt = f"{system_prompt}\n\n{user_prompt}"
    payload = {
        "contents": [{"role": "user", "parts": [{"text": combined_prompt}]}],
        "generationConfig": {"responseMimeType": "application/json"}
    }
    headers = {
        "Content-Type": "application/json",
        "x-goog-api-key": GEMINI_API_KEY
    }

    try:
        async with httpx.AsyncClient() as client:
            response = await client.post(api_url, json=payload, headers=headers, timeout=10.0)

            if not response.is_success:
                print(f"-> âŒ [Gemini AI] {ticker} ìš”ì²­ ì‹¤íŒ¨ (HTTP {response.status_code}): {response.text}")
                response.raise_for_status()

            result = response.json()

            if 'candidates' not in result:
                if 'error' in result:
                     print(f"-> âŒ [Gemini AI] {ticker} Vertex AI ì˜¤ë¥˜: {result['error']['message']}")
                else:
                     print(f"-> âŒ [Gemini AI] {ticker} ë¶„ì„ ì‹¤íŒ¨: ì‘ë‹µì— 'candidates' ì—†ìŒ. {result}")
                return 50

            response_text = result.get('candidates', [{}])[0].get('content', {}).get('parts', [{}])[0].get('text', '{}')

            # --- âœ… [ìˆ˜ì •] ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ ì œê±° ë¡œì§ ì¶”ê°€ ---
            cleaned_text = response_text.strip()
            if cleaned_text.startswith("```json"):
                cleaned_text = cleaned_text[7:]
            if cleaned_text.endswith("```"):
                cleaned_text = cleaned_text[:-3]
            cleaned_text = cleaned_text.strip()

            try:
                score_data = json.loads(cleaned_text)
                score = int(score_data.get("probability_score", 50))
                reasoning = score_data.get("reasoning", "No reasoning provided.")
                print(f"-> [Gemini AI] {ticker}: ìƒìŠ¹ í™•ë¥  {score}% (ì´ìœ : {reasoning})")
                return score
            except json.JSONDecodeError:
                print(f"-> âŒ [Gemini AI] {ticker} ë¶„ì„ ì‹¤íŒ¨: AI ì‘ë‹µì´ ìœ íš¨í•œ JSONì´ ì•„ë‹˜. ì‘ë‹µ: {response_text}")
                return 50

    except Exception as e:
        if 'response' not in locals():
            print(f"-> âŒ [Gemini AI] {ticker} ë¶„ì„ ì‹¤íŒ¨: {e}")
        return 50
# --- ğŸ”¼ [ìˆ˜ì • ì™„ë£Œ] ğŸ”¼ ---


def init_db():
    """PostgreSQL DBì™€ í…Œì´ë¸”ì„ ìƒì„±í•©ë‹ˆë‹¤."""
    conn = None
    try:
        if not DATABASE_URL:
            print("âŒ [DB] DATABASE_URLì´ ì„¤ì •ë˜ì§€ ì•Šì•„ ì´ˆê¸°í™”ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
            return

        conn = get_db_connection()
        cursor = conn.cursor()

        cursor.execute("""
        CREATE TABLE IF NOT EXISTS status (
            key TEXT PRIMARY KEY,
            value TEXT NOT NULL,
            last_updated TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        )
        """)
        cursor.execute("""
        CREATE TABLE IF NOT EXISTS signals (
            id SERIAL PRIMARY KEY,
            ticker TEXT NOT NULL,
            price REAL NOT NULL,
            time TIMESTAMP NOT NULL
        )
        """)
        cursor.execute("""
        CREATE TABLE IF NOT EXISTS recommendations (
            id SERIAL PRIMARY KEY,
            ticker TEXT NOT NULL UNIQUE,
            price REAL NOT NULL,
            time TIMESTAMP NOT NULL,
            probability_score INTEGER
        )
        """)
        cursor.execute("""
        CREATE TABLE IF NOT EXISTS posts (
            id SERIAL PRIMARY KEY,
            author TEXT NOT NULL,
            content TEXT NOT NULL,
            time TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        )
        """)
        cursor.execute("""
        CREATE TABLE IF NOT EXISTS fcm_tokens (
            id SERIAL PRIMARY KEY,
            token TEXT NOT NULL UNIQUE,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        )
        """)
        conn.commit()

        try:
            cursor.execute("ALTER TABLE recommendations ADD COLUMN probability_score INTEGER")
            conn.commit()
            print("-> [DB] 'recommendations' í…Œì´ë¸”ì— 'probability_score' ì»¬ëŸ¼ ì¶”ê°€ ì‹œë„ ì™„ë£Œ.")
        except psycopg2.Error as e:
            if e.pgcode == '42701':
                pass
            else:
                raise

        cursor.close()
        conn.close()
        print(f"âœ… [DB] PostgreSQL í…Œì´ë¸” ì´ˆê¸°í™” ì„±ê³µ.")
    except Exception as e:
        if conn: conn.close()
        print(f"âŒ [DB] PostgreSQL ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")


def send_discord_alert(ticker, price, type="signal", probability_score=50):
    if not DISCORD_WEBHOOK_URL or "YOUR_DISCORD" in DISCORD_WEBHOOK_URL or len(DISCORD_WEBHOOK_URL) < 50:
        print(f"ğŸ”” [ì•Œë¦¼] {ticker} @ ${price} (ë””ìŠ¤ì½”ë“œ URL ë¯¸ì„¤ì •)")
        return

    if type == "signal":
        content = f"ğŸš€ **WAE í­ë°œ ì‹ í˜¸** ğŸš€\n**{ticker}** @ **${price}**\n**AI ìƒìŠ¹ í™•ë¥ : {probability_score}%**"
    else:
        content = f"ğŸ’¡ **ì •ì„ ì…‹ì—… (ì¶”ì²œ)** ğŸ’¡\n**{ticker}** @ **${price}**\n**AI ìƒìŠ¹ í™•ë¥ : {probability_score}%**"

    data = {"content": content}
    try:
        requests.post(DISCORD_WEBHOOK_URL, json=data)
        print(f"ğŸ”” [ì•Œë¦¼] {ticker} @ ${price} (ë””ìŠ¤ì½”ë“œ ì „ì†¡ ì™„ë£Œ)")
    except Exception as e:
        print(f"[ì•Œë¦¼ ì˜¤ë¥˜] {ticker} ë””ìŠ¤ì½”ë“œ ì „ì†¡ ì‹¤íŒ¨: {e}")

# --- ğŸ”½ [ìˆ˜ì •ë¨] FCM í‘¸ì‹œ ì•Œë¦¼ ë°œì†¡ í•¨ìˆ˜ ğŸ”½ ---
def send_fcm_notification(ticker, price, probability_score):
    """DBì˜ ëª¨ë“  í† í°ì— FCM í‘¸ì‹œ ì•Œë¦¼ì„ ë°œì†¡í•©ë‹ˆë‹¤."""
    if not VAPID_PRIVATE_KEY:
        print("ğŸ”” [FCM] VAPID_PRIVATE_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•„ í‘¸ì‹œ ì•Œë¦¼ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
        return

    conn = None
    try:
        conn = get_db_connection()
        cursor = conn.cursor()
        cursor.execute("SELECT token FROM fcm_tokens")
        tokens = cursor.fetchall()
        cursor.close()
        conn.close()

        if not tokens:
            print("ğŸ”” [FCM] DBì— ë“±ë¡ëœ ì•Œë¦¼ êµ¬ë…ìê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        message_data = json.dumps({
            "title": f"ğŸš€ AI Signal: {ticker}",
            "body": f"New setup detected @ ${price} (AI Score: {probability_score}%)",
            "icon": "/static/images/danso_logo.png"
        })

        print(f"ğŸ”” [FCM] {len(tokens)}ëª…ì˜ êµ¬ë…ìì—ê²Œ {ticker} ì•Œë¦¼ ë°œì†¡ ì‹œë„...")

        for (token_str,) in tokens:
            try:
                # --- âœ… [ìˆ˜ì •] í† í° í˜•ì‹ ì˜¤ë¥˜ ë°©ì–´ ë¡œì§ ê°•í™” ---
                if not token_str:
                    continue
                subscription_info = json.loads(token_str)
                # --- âœ… ì—¬ê¸°ê¹Œì§€ ìˆ˜ì • ---

                webpush(
                    subscription_info=subscription_info,
                    data=message_data,
                    vapid_private_key=VAPID_PRIVATE_KEY,
                    vapid_claims={"sub": VAPID_EMAIL}
                )
            except json.JSONDecodeError:
                # [ìˆ˜ì •] JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ, í•´ë‹¹ í† í°ë§Œ ê±´ë„ˆë›°ê³  ë¡œê·¸ ë‚¨ê¹€
                print(f"âŒ [FCM] í† í° í˜•ì‹ ì˜¤ë¥˜ (ìœ íš¨í•œ JSONì´ ì•„ë‹˜). ê±´ë„ˆëœë‹ˆë‹¤: {token_str[:75]}...")
                continue
            except WebPushException as ex:
                print(f"âŒ [FCM] í† í° ì „ì†¡ ì‹¤íŒ¨: {ex}")
                # ì°¸ê³ : ë§Œë£Œëœ í† í°(410, 404)ì€ DBì—ì„œ ì‚­ì œí•˜ëŠ” ë¡œì§ ì¶”ê°€ ê¶Œì¥
            except Exception as e:
                print(f"âŒ [FCM] ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜ ë°œìƒ: {e}")

        print(f"âœ… [FCM] {len(tokens)}ëª…ì—ê²Œ ì•Œë¦¼ ë°œì†¡ ì™„ë£Œ.")

    except Exception as e:
        if conn: conn.close()
        print(f"âŒ [FCM] í‘¸ì‹œ ì•Œë¦¼ ë°œì†¡ ì¤‘ DB ì˜¤ë¥˜: {e}")
# --- ğŸ”¼ [ìˆ˜ì • ì™„ë£Œ] ğŸ”¼ ---


def log_signal(ticker, price, probability_score=50):
    conn = None
    try:
        conn = get_db_connection()
        cursor = conn.cursor()
        cursor.execute("INSERT INTO signals (ticker, price, time) VALUES (%s, %s, %s)",
                       (ticker, price, datetime.now()))
        conn.commit()
        cursor.close()
        conn.close()
    except Exception as e:
        if conn: conn.close()
        print(f"âŒ [DB] 'signals' ì €ì¥ ì‹¤íŒ¨: {e}")


def log_recommendation(ticker, price, probability_score=50):
    conn = None
    try:
        conn = get_db_connection()
        cursor = conn.cursor()
        cursor.execute("""
        INSERT INTO recommendations (ticker, price, time, probability_score)
        VALUES (%s, %s, %s, %s)
        ON CONFLICT (ticker) DO NOTHING
        """,
                       (ticker, price, datetime.now(), probability_score))
        conn.commit()
        is_new_rec = cursor.rowcount > 0
        cursor.close()
        conn.close()
        return is_new_rec
    except Exception as e:
        if conn: conn.close()
        print(f"âŒ [DB] 'recommendations' ì €ì¥ ì‹¤íŒ¨: {e}")
        return False


def find_active_tickers():
    if not POLYGON_API_KEY:
        print(f"-> âŒ [ì‚¬ëƒ¥ê¾¼] 1ë‹¨ê³„ ìŠ¤ìº” ì˜¤ë¥˜: POLYGON_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return set()

    print(f"\n[ì‚¬ëƒ¥ê¾¼] 1ë‹¨ê³„: 'Top Gainers' (ì¡°ê±´: ${MAX_PRICE} ë¯¸ë§Œ) ìŠ¤ìº” ì¤‘...")
    url = f"https://api.polygon.io/v2/snapshot/locale/us/markets/stocks/gainers?apiKey={POLYGON_API_KEY}"
    tickers_to_watch = set()
    try:
        response = requests.get(url)
        response.raise_for_status()
        data = response.json()
        if data.get('status') == 'OK':
            for ticker in data.get('tickers', []):
                price = ticker.get('lastTrade', {}).get('p', 999)
                ticker_symbol = ticker.get('ticker')
                is_price_ok = price <= MAX_PRICE
                if is_price_ok and ticker_symbol:
                    tickers_to_watch.add(ticker_symbol)
                if len(tickers_to_watch) >= TOP_N: break
            print(f"-> [ì‚¬ëƒ¥ê¾¼] 1ë‹¨ê³„ ìŠ¤ìº” ì™„ë£Œ. ì´ {len(tickers_to_watch)}ê°œ ì¢…ëª© í¬ì°©.")
            return tickers_to_watch
    except Exception as e:
        print(f"-> âŒ [ì‚¬ëƒ¥ê¾¼] 1ë‹¨ê³„ ìŠ¤ìº” ì˜¤ë¥˜ (API í‚¤/í•œë„ í™•ì¸): {e}")
        return tickers_to_watch


async def handle_msg(msg_list):
    global ticker_minute_history, ticker_tick_history
    m_fast, m_slow, m_sig = WAE_MACD; bb_len, bb_std = WAE_BB
    T, K, S = ICHIMOKU_SHORT

    minute_data = []
    for msg in msg_list:
        ticker = msg.get('sym')
        if not ticker:
            continue

        if msg.get('ev') == 'T':
            if ticker not in ticker_tick_history:
                ticker_tick_history[ticker] = []
            ticker_tick_history[ticker].append([msg.get('t'), msg.get('p'), msg.get('s')])
            if len(ticker_tick_history[ticker]) > 1000:
                ticker_tick_history[ticker] = ticker_tick_history[ticker][-1000:]

        elif msg.get('ev') == 'AM':
            print(f"-> [ì—”ì§„ v10.0] 1ë¶„ë´‰ ë°ì´í„° ìˆ˜ì‹ : {ticker} @ ${msg.get('c')} (Vol: {msg.get('v')})")
            minute_data.append(msg)

    for msg in minute_data:
        ticker = msg.get('sym')

        if ticker not in ticker_minute_history:
            ticker_minute_history[ticker] = pd.DataFrame(columns=['o', 'h', 'l', 'c', 'v', 't'])
            ticker_minute_history[ticker].set_index('t', inplace=True)

        timestamp = pd.to_datetime(msg.get('s'), unit='ms')
        new_row = {'o': msg.get('o'), 'h': msg.get('h'), 'l': msg.get('l'), 'c': msg.get('c'), 'v': msg.get('v')}
        ticker_minute_history[ticker].loc[timestamp] = new_row

        if len(ticker_minute_history[ticker]) > 60:
            ticker_minute_history[ticker] = ticker_minute_history[ticker].iloc[-60:]

        df_raw = ticker_minute_history[ticker].copy()

        if len(df_raw) < MIN_DATA_REQ: continue

        df = df_raw.resample('1min').agg({
            'o': 'first', 'h': 'max', 'l': 'min', 'c': 'last', 'v': 'sum'
        })

        if ticker in ticker_tick_history and len(ticker_tick_history[ticker]) > 0:
            try:
                ticks_df = pd.DataFrame(ticker_tick_history[ticker], columns=['t', 'p', 's'])
                ticks_df['t'] = pd.to_datetime(ticks_df['t'], unit='ms')
                ticks_df.set_index('t', inplace=True)

                df['c'] = df['c'].combine_first(ticks_df['p'].resample('1min').last())
                df['o'] = df['o'].combine_first(ticks_df['p'].resample('1min').first())
                df['h'] = df['h'].combine_first(ticks_df['p'].resample('1min').max())
                df['l'] = df['l'].combine_first(ticks_df['p'].resample('1min').min())
                df['v'] = df['v'].combine_first(ticks_df['s'].resample('1min').sum())

                ticker_tick_history[ticker] = ticker_tick_history[ticker][-100:]

            except Exception as e:
                print(f"-> [v9.0 í‹± ë³´ê°„ ì‹¤íŒ¨] {ticker}: {e}")

        df.interpolate(method='linear', inplace=True)
        df.ffill(inplace=True)
        df.bfill(inplace=True)

        if len(df) < MIN_DATA_REQ:
            continue

        df.rename(columns={'c': 'close', 'h': 'high', 'l': 'low', 'o': 'open', 'v': 'volume'}, inplace=True)

        df.ta.macd(fast=m_fast, slow=m_slow, signal=m_sig, append=True)
        df.ta.bbands(length=bb_len, std=bb_std, append=True)
        df.ta.atr(length=WAE_ATR, append=True)
        df.ta.cmf(length=WAE_CMF, append=True)
        df.ta.obv(append=True)
        df.ta.rsi(length=RSI_LENGTH, append=True)
        df.ta.ichimoku(tenkan=T, kijun=K, senkou=S, append=True)

        MACD_COL = next((c for c in df.columns if c.startswith('MACD_')), None)
        BB_UP_COL = next((c for c in df.columns if c.startswith('BBU_')), None)
        BB_LOW_COL= next((c for c in df.columns if c.startswith('BBL_')), None)
        ATR_COL = next((c for c in df.columns if c.startswith('ATRr_')), None)
        CMF_COL = next((c for c in df.columns if c.startswith('CMF_')), None)
        RSI_COL = next((c for c in df.columns if c.startswith('RSI_')), None)
        SENKOU_A_COL = next((c for c in df.columns if c.startswith('ISA_')), None)
        SENKOU_B_COL = next((c for c in df.columns if c.startswith('ISB_')), None)
        TENKAN_COL = next((c for c in df.columns if c.startswith('ITS_')), None)
        KIJUN_COL = next((c for c in df.columns if c.startswith('IKS_')), None)
        CHIKOU_COL = next((c for c in df.columns if c.startswith('ICS_')), None)

        if not all([MACD_COL, BB_UP_COL, BB_LOW_COL, ATR_COL, CMF_COL, RSI_COL,
                    SENKOU_A_COL, SENKOU_B_COL, TENKAN_COL, KIJUN_COL, CHIKOU_COL]):
            continue

        df['t1'] = (df[MACD_COL] - df[MACD_COL].shift(1)) * WAE_SENSITIVITY
        df['e1'] = df[BB_UP_COL] - df[BB_LOW_COL]
        df['deadZone'] = df[ATR_COL] * WAE_ATR_MULT

        if len(df) < MIN_DATA_REQ: continue

        last = df.iloc[-1]; prev = df.iloc[-2]

        try:
            cond_wae_momentum = (last['t1'] > last['e1']) and (last['t1'] > last['deadZone'])
            cond_volume = (last[CMF_COL] > 0) and (last['OBV'] > prev['OBV'])
            cond_rsi = (WAE_RSI_RANGE[0] < last[RSI_COL] < WAE_RSI_RANGE[1])

            cloud_a_current = df[SENKOU_A_COL].iloc[-K]; cloud_b_current = df[SENKOU_B_COL].iloc[-K]
            cloud_top = max(cloud_a_current, cloud_b_current);
            is_above_cloud = last['close'] > cloud_top
            tk_cross_bullish = (prev[TENKAN_COL] < prev[KIJUN_COL]) and (last[TENKAN_COL] > last[KIJUN_COL])
            cond_ichimoku_trend = is_above_cloud and tk_cross_bullish

            cloud_thickness = abs(cloud_a_current - cloud_b_current) / last['close'] * 100
            dist_bull = (last['close'] - cloud_top) / last['close'] * 100
            cond_cloud_shape = (cloud_thickness >= CLOUD_THICKNESS) and (0 <= dist_bull <= CLOUD_PROXIMITY)

            chikou = last[CHIKOU_COL]
            price_K_ago = df['close'].iloc[-K]
            cond_chikou = chikou > price_K_ago

            engine_1_pass = (cond_wae_momentum and cond_rsi)
            engine_2_pass = (cond_cloud_shape and cond_volume and cond_rsi)

            if engine_1_pass or engine_2_pass:
                conditions_data = {
                    "engine_1_pass (Explosion)": bool(engine_1_pass),
                    "engine_2_pass (Setup)": bool(engine_2_pass),
                    "wae_momentum": bool(cond_wae_momentum),
                    "rsi_ok": bool(cond_rsi),
                    "volume_ok": bool(cond_volume),
                    "cloud_shape_ok (20%)": bool(cond_cloud_shape),
                    "ichimoku_trend_ok": bool(cond_ichimoku_trend),
                    "chikou_ok": bool(cond_chikou),
                    "rsi_value": float(round(last[RSI_COL], 2)),
                    "cmf_value": float(round(last[CMF_COL], 2)),
                    "cloud_distance_percent": float(round(dist_bull, 2))
                }

                probability_score = await get_gemini_probability(ticker, conditions_data)

                print(f"ğŸ’¡ğŸ’¡ğŸ’¡ [í†µí•© ì—”ì§„ v5.1] {ticker} @ ${last['close']:.4f} (AI Score: {probability_score}%) ğŸ’¡ğŸ’¡ğŸ’¡")
                is_new_rec = log_recommendation(ticker, float(last['close']), probability_score)

                if is_new_rec:
                    send_discord_alert(ticker, float(last['close']), "recommendation", probability_score)
                    send_fcm_notification(ticker, float(last['close']), probability_score)

        except Exception as e:
            print(f"-> âŒ [ì—”ì§„ CRASH] {ticker} ë¶„ì„ ì¤‘ ì¹˜ëª…ì  ì˜¤ë¥˜: {e}")
            pass


async def websocket_engine(websocket):
    try:
        async for message in websocket:
            try:
                data_list = json.loads(message)
                await handle_msg(data_list)
            except Exception as e:
                print(f"-> âŒ [v9.0 ìˆ˜ì‹  ì—”ì§„ CRASH] 'handle_msg' í˜¸ì¶œ ì‹¤íŒ¨: {e}")

    except websockets.exceptions.ConnectionClosed as e:
        print(f"-> âŒ [ì—”ì§„ v9.0] ì›¹ì†Œì¼“ ì—°ê²° ì¢…ë£Œ: {e.reason}")
    except Exception as e:
        print(f"-> âŒ [ì—”ì§„ v9.0] ì›¹ì†Œì¼“ ì˜¤ë¥˜: {e}")


async def periodic_scanner(websocket):
    current_subscriptions = set()

    while True:
        try:
            print(f"\n[ì‚¬ëƒ¥ê¾¼] (v9.7) 7ë¶„ ì£¼ê¸° ì‹œì‘. 'ì‹ í˜¸ í”¼ë“œ' (signals, recommendations) DBë¥¼ ì²­ì†Œí•©ë‹ˆë‹¤...")
            conn = get_db_connection()
            cursor = conn.cursor()
            cursor.execute("TRUNCATE TABLE signals")
            cursor.execute("TRUNCATE TABLE recommendations")
            conn.commit()
            cursor.close()
            conn.close()
            print("-> [ì‚¬ëƒ¥ê¾¼] DB ì²­ì†Œ ì™„ë£Œ.")
        except Exception as e:
            print(f"-> âŒ [ì‚¬ëƒ¥ê¾¼] DB ì²­ì†Œ ì‹¤íŒ¨: {e}")

        new_tickers = find_active_tickers()
        tickers_to_add = new_tickers - current_subscriptions
        tickers_to_remove = current_subscriptions - new_tickers

        try:
            if tickers_to_add:
                print(f"[ì‚¬ëƒ¥ê¾¼] {len(tickers_to_add)}ê°œ ì‹ ê·œ ì¢…ëª© êµ¬ë… ì‹œì‘: {tickers_to_add}")
                for ticker in tickers_to_add:
                    params_str = f"AM.{ticker},T.{ticker}"
                    sub_payload = json.dumps({"action": "subscribe", "params": params_str})
                    await websocket.send(sub_payload)
                    await asyncio.sleep(0.1)
                print("[ì‚¬ëƒ¥ê¾¼] ì‹ ê·œ êµ¬ë… ì™„ë£Œ.")

            if tickers_to_remove:
                print(f"[ì‚¬ëƒ¥ê¾¼] {len(tickers_to_remove)}ê°œ ì‹ì€ ì¢…ëª© êµ¬ë… í•´ì§€: {tickers_to_remove}")
                for ticker in tickers_to_remove:
                    params_str = f"AM.{ticker},T.{ticker}"
                    unsub_payload = json.dumps({"action": "unsubscribe", "params": params_str})
                    await websocket.send(unsub_payload)
                    await asyncio.sleep(0.1)
                print("[ì‚¬ëƒ¥ê¾¼] êµ¬ë… í•´ì§€ ì™„ë£Œ.")

        except websockets.exceptions.ConnectionClosed:
             print("-> âŒ [ì‚¬ëƒ¥ê¾¼] êµ¬ë…/í•´ì§€ ì‹¤íŒ¨: ì›¹ì†Œì¼“ ì—°ê²°ì´ ì´ë¯¸ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. (ì¬ì—°ê²° ì‹œë„)")
             raise
        except Exception as e:
            print(f"-> âŒ [ì‚¬ëƒ¥ê¾¼] êµ¬ë…/í•´ì§€ ì‹¤íŒ¨: {e}")

        current_subscriptions = new_tickers

        status_tickers_list = [{"ticker": ticker, "is_new": ticker in tickers_to_add} for ticker in current_subscriptions]
        status_data = {
            'last_scan_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            'watching_count': len(current_subscriptions),
            'watching_tickers': status_tickers_list
        }
        try:
            status_json_string = json.dumps(status_data)
            conn = get_db_connection()
            cursor = conn.cursor()
            cursor.execute("""
            INSERT INTO status (key, value, last_updated)
            VALUES (%s, %s, %s)
            ON CONFLICT (key) DO UPDATE SET
                value = EXCLUDED.value,
                last_updated = EXCLUDED.last_updated
            """,
                           ('status_data', status_json_string, datetime.now()))
            conn.commit()
            cursor.close()
            conn.close()
        except Exception as e:
            print(f"âŒ [DB] 'status' ì €ì¥ ì‹¤íŒ¨: {e}")

        print(f"\n[ì‚¬ëƒ¥ê¾¼] 7ë¶„(420ì´ˆ) í›„ ë‹¤ìŒ ìŠ¤ìº”ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
        await asyncio.sleep(420)


async def manual_keepalive(websocket):
    try:
        while True:
            await websocket.ping()
            print("-> [Keepalive] Ping ì „ì†¡ (ì—°ê²° ìœ ì§€)")
            await asyncio.sleep(20)
    except websockets.exceptions.ConnectionClosed:
        print("-> [Keepalive] ì—°ê²° ì¢…ë£Œë¨. Ping ì¤‘ë‹¨.")
    except Exception as e:
        print(f"-> âŒ [Keepalive] í•‘ ì „ì†¡ ì¤‘ ì˜¤ë¥˜: {e}")


async def main():
    required_vars = ['POLYGON_API_KEY', 'DATABASE_URL', 'GEMINI_API_KEY', 'GCP_PROJECT_ID']
    for var in required_vars:
        if not globals().get(var) or ("YOUR_PROJECT_ID" in str(globals().get(var))):
            print(f"âŒ [ë©”ì¸] í™˜ê²½ ë³€ìˆ˜ '{var}'ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ìŠ¤ìºë„ˆë¥¼ ì‹œì‘í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return

    if not VAPID_PRIVATE_KEY:
        print("âš ï¸ [ë©”ì¸] VAPID_PRIVATE_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. FCM í‘¸ì‹œ ì•Œë¦¼ì´ ë¹„í™œì„±í™”ë©ë‹ˆë‹¤.")

    print("ìŠ¤ìºë„ˆ V15.5 (ì˜¤ë¥˜ ìˆ˜ì • ë²„ì „)ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
    uri = "wss://socket.polygon.io/stocks"

    while True:
        try:
            async with websockets.connect(uri, ping_interval=None, ping_timeout=300) as websocket:
                print(f"[ë©”ì¸] ì›¹ì†Œì¼“ {uri} ì—°ê²° ì„±ê³µ.")

                response = await websocket.recv()
                print(f"[ë©”ì¸] ì—°ê²° ì‘ë‹µ: {response}")
                if '"status":"connected"' not in str(response):
                     print("-> âŒ [ë©”ì¸] ë¹„ì •ìƒ ì—°ê²° ì‘ë‹µ. 10ì´ˆ í›„ ì¬ì‹œë„...")
                     await asyncio.sleep(10)
                     continue

                api_key_to_use = POLYGON_API_KEY or ""
                print(f"[ë©”ì¸] API í‚¤ ({api_key_to_use[:4]}...)ë¡œ 'ìˆ˜ë™ ì¸ì¦'ì„ ì‹œë„í•©ë‹ˆë‹¤...")
                auth_payload = json.dumps({"action": "auth", "params": api_key_to_use})
                await websocket.send(auth_payload)

                response = await websocket.recv()
                print(f"[ë©”ì¸] ì¸ì¦ ì‘ë‹µ: {response}")

                if '"status":"auth_success"' in str(response):
                    print("-> âœ… [ë©”ì¸] 'ìˆ˜ë™ ì¸ì¦' ì„±ê³µ! 3ê°œ ë¡œë´‡(ì‚¬ëƒ¥ê¾¼, ì—”ì§„, í•‘)ì„ ì‹œì‘í•©ë‹ˆë‹¤.")

                    watcher_task = websocket_engine(websocket)
                    scanner_task = periodic_scanner(websocket)
                    keepalive_task = manual_keepalive(websocket)

                    await asyncio.gather(watcher_task, scanner_task, keepalive_task)
                else:
                    print("-> âŒ [ë©”ì¸] 'ìˆ˜ë™ ì¸ì¦' ì‹¤íŒ¨. 10ì´ˆ í›„ ì¬ì‹œë„...")
                    await asyncio.sleep(10)
                    continue

        except websockets.exceptions.ConnectionClosed as e:
            print(f"-> âŒ [ë©”ì¸] ì›¹ì†Œì¼“ ì—°ê²°ì´ ì˜ˆê¸°ì¹˜ ì•Šê²Œ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤ ({e.code}). 10ì´ˆ í›„ ì¬ì—°ê²°í•©ë‹ˆë‹¤...")
            await asyncio.sleep(10)
        except Exception as e:
            print(f"-> âŒ [ë©”ì¸] ì¹˜ëª…ì  ì˜¤ë¥˜ ë°œìƒ: {e}. 10ì´ˆ í›„ ì¬ì—°ê²°í•©ë‹ˆë‹¤...")
            await asyncio.sleep(10)


if __name__ == "__main__":
    init_db()
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("\n[ë©”ì¸] ì‚¬ìš©ìì— ì˜í•´ í”„ë¡œê·¸ë¨ì´ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")