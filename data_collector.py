import requests
import pandas as pd
import os
import time
from datetime import datetime, timedelta
from concurrent.futures import ThreadPoolExecutor

# ==============================================================================
# 1. CONFIGURATION
# ==============================================================================
# ì‚¬ìš©ì API í‚¤ ì ìš©
POLYGON_API_KEY = os.environ.get('POLYGON_API_KEY')

BASE_URL = "https://api.polygon.io"
DATA_DIR = "datasets"

# ğŸ”¥ [ìˆ˜ì •ë¨] ìˆ˜ì§‘ ê¸°ê°„: ìµœê·¼ 3ê°œì›” (90ì¼)
END_DATE = (datetime.now() - timedelta(days=1)).strftime('%Y-%m-%d')
START_DATE = (datetime.now() - timedelta(days=90)).strftime('%Y-%m-%d')

print(f"ğŸ“… ìˆ˜ì§‘ ê¸°ê°„ ì„¤ì •: {START_DATE} ~ {END_DATE} (ìµœê·¼ 3ê°œì›”)")

# ==============================================================================
# 2. COLLECTOR FUNCTIONS
# ==============================================================================

def get_daily_gainers(date):
    """í•´ë‹¹ ë‚ ì§œì˜ Top Gainers 10ê°œ ì¶”ì¶œ (ìˆ˜ì •ë¨)"""
    url = f"{BASE_URL}/v2/aggs/grouped/locale/us/market/stocks/{date}?adjusted=true&apiKey={POLYGON_API_KEY}"
    try:
        res = requests.get(url).json()
        if 'results' not in res: return []
        
        df = pd.DataFrame(res['results'])
        
        if df.empty or 'v' not in df.columns or 'c' not in df.columns:
            return []

        # ê±°ë˜ëŸ‰ 100ë§Œë¶ˆ ì´ìƒ & 5% ì´ìƒ ìƒìŠ¹ ì¢…ëª© í•„í„°ë§
        df['dollar_vol'] = df['v'] * df['c']
        candidates = df[(df['dollar_vol'] > 1_000_000) & 
                        ((df['c'] - df['o']) / df['o'] > 0.05)]
        
        if candidates.empty: return []

        # ìƒìŠ¹ë¥  ìˆœ ì •ë ¬ í›„ Top 10ë§Œ ì¶”ì¶œ (20 -> 10ìœ¼ë¡œ ë³€ê²½)
        candidates['change'] = (candidates['c'] - candidates['o']) / candidates['o']
        top_10 = candidates.sort_values('change', ascending=False).head(10)['T'].tolist()
        return top_10
    except Exception as e:
        print(f"âŒ [Error] {date} Gainers fetch failed: {e}")
        return []

def download_ticker_data(ticker, date):
    """Tick(Trades), Quote, Aggregate ë°ì´í„° ë‹¤ìš´ë¡œë“œ"""
    save_dir = f"{DATA_DIR}/{date}/{ticker}"
    
    # ì´ë¯¸ Tradesì™€ Quotesê°€ ë‘˜ ë‹¤ ìˆìœ¼ë©´ ìŠ¤í‚µ
    if os.path.exists(save_dir) and \
       os.path.exists(f"{save_dir}/trades.csv") and \
       os.path.exists(f"{save_dir}/quotes.csv"):
        print(f"â© {date} | {ticker} All data exists. Skipping.")
        return

    os.makedirs(save_dir, exist_ok=True)
    
    # 1. Aggregates (1min)
    try:
        url_agg = f"{BASE_URL}/v2/aggs/ticker/{ticker}/range/1/minute/{date}/{date}?adjusted=true&sort=asc&limit=50000&apiKey={POLYGON_API_KEY}"
        res = requests.get(url_agg).json()
        if 'results' in res:
            pd.DataFrame(res['results']).to_csv(f"{save_dir}/agg.csv", index=False)
    except: pass

    # 2. Trades (Ticks)
    try:
        url_trade = f"{BASE_URL}/v3/trades/{ticker}?timestamp={date}&limit=50000&apiKey={POLYGON_API_KEY}"
        res = requests.get(url_trade).json()
        if 'results' in res:
            pd.DataFrame(res['results']).to_csv(f"{save_dir}/trades.csv", index=False)
    except: pass

    # 3. Quotes (NBBO) - ğŸ”¥ [ì¤‘ìš”] ì£¼ì„ í•´ì œë¨ (ë‹¤ìš´ë¡œë“œ ì‹¤í–‰)
    try:
        # QuotesëŠ” ë°ì´í„°ê°€ ë§ì•„ì„œ limitë¥¼ ìµœëŒ€ë¡œ ëŠ˜ë¦¼
        url_quote = f"{BASE_URL}/v3/quotes/{ticker}?timestamp={date}&limit=50000&apiKey={POLYGON_API_KEY}"
        res = requests.get(url_quote).json()
        if 'results' in res:
            pd.DataFrame(res['results']).to_csv(f"{save_dir}/quotes.csv", index=False)
            # print(f"   â””â”€ Quotes saved for {ticker}") # ë¡œê·¸ ë„ˆë¬´ ë§ìœ¼ë©´ ì£¼ì„ ì²˜ë¦¬
    except Exception as e: 
        print(f"   âš ï¸ Quote download failed: {e}")
    
    print(f"âœ… {date} | {ticker} Data Saved")

def main():
    if not POLYGON_API_KEY:
        print("âŒ Error: API Key Missing!")
        return

    # ì˜ì—…ì¼ ê¸°ì¤€ ë‚ ì§œ ë¦¬ìŠ¤íŠ¸
    dates = pd.date_range(start=START_DATE, end=END_DATE, freq='B') 
    
    print(f"ğŸ“Š ì´ ìˆ˜ì§‘ ì˜ˆì •ì¼: {len(dates)}ì¼ (Top 10 ì¢…ëª©/ì¼)")
    print(f"âš ï¸ ì£¼ì˜: í˜¸ê°€(Quotes) ë°ì´í„° í¬í•¨ìœ¼ë¡œ ìš©ëŸ‰ì´ í½ë‹ˆë‹¤. ë””ìŠ¤í¬ ê³µê°„ì„ í™•ì¸í•˜ì„¸ìš”.")

    for d in dates:
        date_str = d.strftime('%Y-%m-%d')
        print(f"\nğŸ“… Processing {date_str}...")
        
        gainers = get_daily_gainers(date_str)
        
        if not gainers:
            print("   No gainers found or holiday.")
            continue

        print(f"   Targets: {gainers}")
        
        # ì›Œì»¤ ìˆ˜ 5 ìœ ì§€
        with ThreadPoolExecutor(max_workers=5) as executor:
            for ticker in gainers:
                executor.submit(download_ticker_data, ticker, date_str)
                time.sleep(0.1) 

if __name__ == "__main__":
    main()